{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modular Arithmetic: Language Models Solve Math Digit by Digit\n",
        "## Download nececcery data\n",
        "how to set up the pyvene library with support for Olmo2 as an intervenable model, and how to download the corresponding data and code for the transformer digit arithmetic project.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIztQfmuPlzv"
      },
      "source": [
        "##### Pyvene + Olmo2 Setup Guide: If you've previously installed the standard pyvene package, uninstall it first to avoid conflicts.\n",
        "\n",
        "##### Install Our Custom pyvene with Olmo2 Support https://anonymous.4open.science/r/pyvene_Olmo2\n",
        "Download the custom version of pyvene with Olmo2 support from the anonymous repository.\n",
        "Unzip the downloaded archive.\n",
        "Install the package in editable mode so any local changes are reflected without reinstalling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip uninstall -y pyvene  # pyvene has to be uninstalled if a standard version is currently installed\n",
        "# pip install pyvene\n",
        "%cd /content/\n",
        "!wget https://anonymous.4open.science/api/repo/pyvene_Olmo2/zip -O lib.zip\n",
        "!unzip lib.zip -d pyvene_Olmo2\n",
        "%cd pyvene_Olmo2\n",
        "!pip install -e .\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/pyvene_Olmo2')  # Adjust as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Download Digit Arithmetic Code and Data https://anonymous.4open.science/r/tda-C722/\n",
        "Download the dataset and code for the anonymous repository.\n",
        "Unzip the contents into a local directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeyBSXiAPlTn",
        "outputId": "03e4105e-ac4f-4689-bd7f-228d715deea4"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!wget https://anonymous.4open.science/api/repo/transformer-digit-arithmetic-FCBC/zip -O code.zip\n",
        "!unzip code.zip -d transformer-digit-arithmetic\n",
        "%cd transformer-digit-arithmetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQSGxa7hQcKu",
        "outputId": "3c1eaf38-2d37-4e79-83b2-c171d120fe65"
      },
      "outputs": [],
      "source": [
        "import pyvene as pv\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from pyvene import embed_to_distrib, top_vals, format_token\n",
        "from pyvene import (\n",
        "    ZeroIntervention,\n",
        "    IntervenableModel,\n",
        "    VanillaIntervention, Intervention,\n",
        "    RepresentationConfig,\n",
        "    IntervenableConfig,\n",
        "    ConstantSourceIntervention,\n",
        "    LocalistRepresentationIntervention\n",
        ")\n",
        "from huggingface_hub import login\n",
        "import re\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import transformers\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93z_4vN6QivG"
      },
      "source": [
        "## Model Loading Guide (LLAMA & OLMo2)\n",
        "\n",
        "This section describes how to load supported language models (LLama 3 8B or OLMo 2 7B) for use in experiments. It includes Hugging Face login, model selection, and hardware compatibility notes.\n",
        "\n",
        "---\n",
        "\n",
        "### Hardware Requirements\n",
        "\n",
        "| Model         | Approx. VRAM Required | Compatible GPU |\n",
        "|---------------|------------------------|----------------|\n",
        "| LLaMA 3 8B     | ~16 GB                 | A100 / L4       |\n",
        "| OLMo 2 7B      | ~14 GB                 | A100 / L4       |\n",
        "| LLaMA 3 70B    | ‚ùå *Not suitable for Colab* |\n",
        "\n",
        "---\n",
        "\n",
        "### Login to Hugging Face\n",
        "\n",
        "To download and use the **Meta LLaMA** models, you must authenticate with your **Hugging Face access token**.\n",
        "\n",
        "Replace `<replace_with_your_token>` with your actual Hugging Face token.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtGz_kwgQjxm"
      },
      "outputs": [],
      "source": [
        "# Login to Huggingface to get access to model parameters\n",
        "# Paste your token here\n",
        "HugginFace_Token = \"<replace_with_your_token>\"\n",
        "login(HugginFace_Token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Choose a Model\n",
        "\n",
        "Select one of the available models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VmQMDbeQxN2"
      },
      "outputs": [],
      "source": [
        "# Available models\n",
        "model_name = \"Llama-3-8B\"  # Options: \"Llama-3-8B\", \"Llama-3-70B\", \"Olmo-2-7B\"\n",
        "\n",
        "models = {\n",
        "    \"Llama-3-8B\": \"meta-llama/Meta-Llama-3-8B\",\n",
        "    \"Llama-3-70B\": \"meta-llama/Meta-Llama-3-70B\",\n",
        "    \"Olmo-2-7B\": \"allenai/OLMo-2-1124-7B\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Model and Tokenizer\n",
        "Load the model and tokenizer using transformers. This script will automatically use GPU (cuda) if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "ed08da4944744403baedc3abacf26a69",
            "0e6c85bb6afa446e8c22b9bdecf9ebac",
            "1fd8359385d4473b9249736a61dbc9ef",
            "4af381af35af4fe1a99c1a827ce069ef",
            "e77b709fd4c04e1aa8162558af5b40fa",
            "6cd96f2861df485c98963cee8fd11f9f",
            "294edc2636974381973a4981ca576e96",
            "34a5cea0e4f344ee999db2d8b94023ae",
            "67b063795012434ca84fda35af94a22f",
            "11644d5a8dbb4bd8a17cee2967f09c44",
            "c69045c248594ea594850243be21de93"
          ]
        },
        "id": "gCBzhTaDQx8O",
        "outputId": "2452d127-9160-4afb-dc3f-bc6f1530a043"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set parameters\n",
        "params = {\n",
        "    'model_name': models[model_name],\n",
        "    'device': \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(params['model_name'])\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  params['model_name'], \n",
        "  torch_dtype=torch.float16).to(params['device'])\n",
        "\n",
        "# Confirm device\n",
        "print(f\"Using device: {params['device']}\")\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Using GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbk3s-9eQ8OR"
      },
      "source": [
        "## Digit Circuit Intervention Setup\n",
        "\n",
        "This guide explains how to configure and run interventions on **digit circuits** in transformer models using precomputed **Fisher scores**. You can choose specific parameters like digit position, arithmetic task, operand type, and apply thresholding to identify meaningful MLP dimensions for intervention.\n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "\n",
        "- Identify MLP neurons involved in **digit representation** (hundredth, tenth, unit).\n",
        "- Perform interventions based on:\n",
        "  - Arithmetic **task** (`addition` / `subtraction`)\n",
        "  - **Operand** type (`op1` or `op2`)\n",
        "  - Precomputed **Fisher score thresholds**\n",
        "- Extract and map MLP neuron indices per layer that cross the selected Fisher score threshold.\n",
        "\n",
        "---\n",
        "\n",
        "## Configuration\n",
        "\n",
        "### Select the digit position (label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xUTzMfLQ9tP"
      },
      "outputs": [],
      "source": [
        "# labels\n",
        "label = \"hundredth\"  # Options: \"hundredth\", \"tenth\", \"unit\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Choose the arithmetic task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# task (operator)\n",
        "task = \"addition\"  # Options: \"addition\", \"subtraction\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select the operand type: (op1 + op2 = ..) two variation either fix op1 or op2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# which oeprand\n",
        "operand = \"op1\"  # Options: \"op1\", \"op2\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Load Intervention Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the specific intervention dataset based on task and operand\n",
        "input_file = f\"Intervention_Data/intervention_data_{task}_{operand}.json\"\n",
        "with open(input_file, \"r\") as f:\n",
        "    data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Load Layer Set and Threshold\n",
        "These are precomputed and based on the best-performing layers and Fisher thresholds per model/task/operand configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load selected layers for intervention\n",
        "with open(\"intervene_layers.json\", \"r\") as f:\n",
        "    layer_sets = json.load(f)\n",
        "layer_set = layer_sets[model_name][task][operand]\n",
        "\n",
        "# Load corresponding Fisher score threshold\n",
        "with open(\"fisher_scores_threshold_map.json\", \"r\") as f:\n",
        "    threshold_map = json.load(f)\n",
        "threshold = threshold_map[model_name][task][operand][label]\n",
        "\n",
        "print(\"Selected layers:\", layer_set)\n",
        "print(\"Fisher threshold:\", threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Extract Digit Circuit Neurons by Threshold\n",
        "\n",
        "For each selected layer, extract neuron indices where the Fisher score exceeds the threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lGuiGwxufMS",
        "outputId": "ff25d60f-7f6f-4f30-f825-2daf39ff0683"
      },
      "outputs": [],
      "source": [
        "# Load Fisher scores for the specified digit label\n",
        "fisher_file = f\"Fisher_Scores/{model_name}/{task}/fisher_scores_{label}.json\"\n",
        "with open(fisher_file, \"r\") as file:\n",
        "    fisher_scores_data = json.load(file)\n",
        "\n",
        "# Output map: layer index ‚Üí list of neuron indices\n",
        "layer_subspaces_map = {}\n",
        "\n",
        "# Filter neurons per layer\n",
        "for layer in layer_set:\n",
        "    key = f\"layer_{layer}\"\n",
        "    if key in fisher_scores_data:\n",
        "        values = fisher_scores_data[key]\n",
        "        indices_above_threshold = [i for i, val in enumerate(values) if val > threshold]\n",
        "        layer_subspaces_map[layer] = indices_above_threshold\n",
        "\n",
        "# Resulting neuron indices to intervene on\n",
        "print(layer_subspaces_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  Notes\n",
        "\n",
        "- You can customize the threshold or layers to perform ablations or sensitivity analyses.\n",
        "- The mappings (layer_sets, threshold_map, fisher_scores_data) are organized to allow plug-and-play selection based on model name, digit position, and task type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ Digit Circuit Interventions ‚Äì Implementation Guide\n",
        "\n",
        "This code performs **causal interventions** on digit-position-specific MLP circuits identified in transformer language models (e.g., LLaMA 3 8B, OLMo 2 7B) using **Fisher-score-selected subspaces**.\n",
        "\n",
        "---\n",
        "\n",
        "##  Goal\n",
        "\n",
        "To verify that specific MLP neurons (identified via high Fisher scores) are **causally responsible** for generating arithmetic result digits at different positions (units, tens, hundreds). This is done through **interchange interventions**: replacing the activations of a ‚Äúbase‚Äù input with those from a ‚Äúsource‚Äù input only at selected subspaces.\n",
        "\n",
        "---\n",
        "\n",
        "##  Setup and Context\n",
        "\n",
        "Before this code runs:\n",
        "- Fisher scores have been computed per digit position.\n",
        "- A threshold has been chosen to select the most important neurons per layer (see Section 3.1 of the paper).\n",
        "- Layer sets are determined where digit information is known to flow (see Section C of the paper).\n",
        "- The JSON files `intervene_layers.json` and `fisher_scores_threshold_map.json` define model/task/digit-specific layer sets and thresholds.\n",
        "\n",
        "---\n",
        "\n",
        "##  Step-by-Step Breakdown\n",
        "\n",
        "###  Iterate over Intervention Examples\n",
        "###  Clean Forward Pass (Baseline)\n",
        "Performs a clean (unmodified) forward pass on the base sentence to record its top-100 predictions.\n",
        "\n",
        "The logits of the final token are extracted.\n",
        "A softmax is applied to obtain a probability distribution.\n",
        "Top 100 tokens and their probabilities are stored for comparison.\n",
        "###  Interchange Intervention Setup\n",
        "Uses pyvene to define which model component and layer to intervene on (mlp_output of selected layers).\n",
        "\n",
        "Then prepares layer_subspaces_map ‚Üí a dictionary mapping each selected layer to a list of high-Fisher-score neuron indices (i.e., subspaces for that digit-position circuit).\n",
        "###  Run the Intervention\n",
        "This interchange intervention replaces selected neuron activations from the source sentence into the base sentence at the final token's position (see Section 3.2 of the paper).\n",
        "\n",
        "Only neurons that passed the Fisher-score threshold are modified.\n",
        "Only specified layers are intervened on (those known to be causally relevant per digit position).\n",
        "Only the selected digit-position circuit is changed (e.g., the \"hundredth\" digit MLP subspace).\n",
        "\n",
        "###  Post-Intervention Analysis\n",
        "After the intervention, the model output is compared to the baseline. The shift in token probability mass (e.g., from 579 ‚Üí 573) indicates whether the intended digit was selectively changed.\n",
        "\n",
        "This is aligned with the digit-modularity claim in the paper (Section 3.2, Table 2 & 3).\n",
        "\n",
        "###  Save Results\n",
        "Each run‚Äôs clean and intervened top-k distributions are saved as a CSV, enabling quantitative evaluation (e.g., computing probability shift to expected variants, see ¬ß3.2, ¬ß4.1).\n",
        "\n",
        "##  Expected Outcome\n",
        "\n",
        "If the digit circuits are truly modular and causal, intervening on one circuit (e.g., hundredth) should:\n",
        "\n",
        "Shift probability toward the output that only replaces the hundredth digit (e.g., 957 ‚Üí 357)\n",
        "Leave tens and unit digits mostly unchanged.\n",
        "This provides strong causal evidence that digit-wise arithmetic is realized via distinct, compositional subcircuits in LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH3u8vtmRUWv",
        "outputId": "6a160071-0d53-49f9-af27-32d2c5d1acdb"
      },
      "outputs": [],
      "source": [
        "################################################\n",
        "# Perform Digit-Circuit Interventions on each data point #\n",
        "################################################\n",
        "\n",
        "# Iterate through each query in the dataset\n",
        "for j, entry in tqdm(enumerate(data)):\n",
        "    data_entry = []\n",
        "    model_layers = model.config.num_hidden_layers\n",
        "    window_size = 1\n",
        "\n",
        "    sentence = entry[\"one_shot_base\"]\n",
        "    sentence_intervention = entry[\"one_shot_source\"]\n",
        "\n",
        "    base = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Number of tokens\n",
        "    tokenized_input = tokenizer(sentence, return_tensors=\"pt\", return_offsets_mapping=True)\n",
        "    input_ids = tokenized_input[\"input_ids\"].to(device)\n",
        "    num_tokens = input_ids.shape[1]\n",
        "\n",
        "    ############################\n",
        "    # Clean Run for comparison #\n",
        "    ############################\n",
        "\n",
        "    inputs = [tokenizer(sentence, return_tensors=\"pt\").to(device),]\n",
        "    res = model(**inputs[0])\n",
        "\n",
        "    distrib = res.logits\n",
        "    logits = distrib[0][-1]\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the top 10 tokens and their probabilities\n",
        "    top_k = 50\n",
        "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "    # Convert indices to tokens\n",
        "    top_k_tokens = [tokenizer.decode(index.item()) for index in top_k_indices]\n",
        "\n",
        "    # Collect the data\n",
        "    data_temp = []\n",
        "    for token, prob in zip(top_k_tokens, top_k_probs):\n",
        "        data_temp.append({\n",
        "            \"token\": token,\n",
        "            \"prob\": prob.detach().cpu().item()\n",
        "        })\n",
        "\n",
        "    data_entry.append({\"run\": \"clean\", \"top_100\": data_temp})\n",
        "\n",
        "    ###############################################\n",
        "    # Interchange Interventions across layer sets #\n",
        "    ###############################################\n",
        "\n",
        "    # Get the index of the last token using len()\n",
        "    last_token_index = len(base['input_ids'][0]) - 1  # Use len() to get the length of the sequence\n",
        "\n",
        "    # Create intervention for specific layers\n",
        "    config = pv.IntervenableConfig([{\n",
        "        \"layer\": l,\n",
        "        \"component\": \"mlp_output\",\n",
        "        \"intervention_type\": VanillaIntervention\n",
        "        } for l in layer_set] # Pass a list instead of a single layer\n",
        "    )\n",
        "\n",
        "    pv_model = pv.IntervenableModel(config, model=model)\n",
        "\n",
        "    # Define list of subspaces based on the layer_subspaces_map\n",
        "    # Create an empty list to store the corresponding subspaces for each layer in layer_set\n",
        "    subspaces = []\n",
        "\n",
        "    # Loop over the layers in the current layer_set and fetch corresponding subspaces\n",
        "    for layer in layer_set:\n",
        "        subspaces.append(layer_subspaces_map[layer])\n",
        "\n",
        "    # run an interchange intervention\n",
        "    _, intervened_outputs = pv_model(\n",
        "      # the base input\n",
        "      base=tokenizer(sentence, return_tensors = \"pt\").to(device),\n",
        "      # the source input\n",
        "      sources=tokenizer(sentence_intervention, return_tensors = \"pt\").to(device),\n",
        "      # the location to intervene at (last token)\n",
        "      unit_locations={\"sources->base\": last_token_index},\n",
        "      subspaces = subspaces\n",
        "    )\n",
        "\n",
        "    distrib = intervened_outputs.logits\n",
        "    logits = distrib[0][-1]\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the top 10 tokens and their probabilities\n",
        "    top_k = 100\n",
        "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "    # Convert indices to tokens\n",
        "    top_k_tokens = [tokenizer.decode(index.item()) for index in top_k_indices]\n",
        "\n",
        "    # Collect the data\n",
        "    data_temp = []\n",
        "    for token, prob in zip(top_k_tokens, top_k_probs):\n",
        "        data_temp.append({\n",
        "            \"token\": token,\n",
        "            \"prob\": prob.detach().cpu().item()\n",
        "        })\n",
        "\n",
        "    data_entry.append({\"run\": \"intervened\", \"top_100\": data_temp})\n",
        "\n",
        "    df = pd.DataFrame(data_entry)\n",
        "\n",
        "    output_dir = f\"Interventions/\"\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create the folder if it doesn't exist\n",
        "\n",
        "    df.to_csv(f\"{output_dir}/intervention_{model_name}_{task}_{operand}_{label}_threshold_{threshold}_{j}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKkH5cxIRo_f"
      },
      "source": [
        "#  Evaluating Digit Circuit Interventions ‚Äî Average Variant Probabilities\n",
        "\n",
        "This script **aggregates and evaluates** the effect of digit-circuit interventions on language model outputs by computing the **average predicted probability** of specific **result variants** across all clean and intervened runs.\n",
        "\n",
        "It operationalizes the causal claims made in the paper, especially regarding **digit-specific influence** of MLP neuron circuits.\n",
        "\n",
        "---\n",
        "\n",
        "##  Goal\n",
        "\n",
        "After each digit-circuit intervention (e.g., modifying only the MLP subspace for the \"hundreds\" digit), we expect:\n",
        "- **One result variant** (e.g., `sbb`) to increase in probability,\n",
        "- While others (e.g., `bsb`, `bbs`, `ssb`, etc.) remain largely unchanged.\n",
        "\n",
        "This script measures that effect **across many examples** by:\n",
        "- Loading `.csv` results for each example,\n",
        "- Extracting top-100 tokens from clean and intervened runs,\n",
        "- Matching them to known variant results (e.g., `sss = fully source result`),\n",
        "- Accumulating and averaging the predicted probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "##  Input Requirements\n",
        "\n",
        "- Folder: `Interventions/`  \n",
        "  Contains per-example `.csv` files of top-100 token distributions.\n",
        "  Each file includes rows like:\n",
        "  \n",
        "  |run| top_100|\n",
        "  |---------------|------------------------|\n",
        "  |clean| [{\"token\": \"579\", \"prob\": 0.94}, ...]|\n",
        "  |intervened| [{\"token\": \"573\", \"prob\": 0.72}, ...]|\n",
        "\n",
        "\n",
        "- In-memory variable: `data`  \n",
        "List of intervention metadata loaded earlier (e.g., from `intervention_data_add_op1.json`).  \n",
        "Each entry must include:\n",
        "    ```json\n",
        "    \"result_variants\": {\n",
        "        \"bbb\": \"579\",\n",
        "        \"sbb\": \"779\",\n",
        "        ...\n",
        "    }\n",
        "\n",
        "\n",
        "##  Core Logic Explained\n",
        "1. Initialize Accumulators\n",
        "- accumulated_probs = { \"clean\": ..., \"intervened\": ... }\n",
        "- counts = { \"clean\": ..., \"intervened\": ... }\n",
        "- For each variant (e.g., \"bsb\", \"sss\"), track:\n",
        "- Sum of predicted probabilities,\n",
        "- Count of appearances across examples.\n",
        "\n",
        "2. Loop Through CSV Files\n",
        "- For each .csv corresponding to a single intervention example:\n",
        "- Extract index j from the filename to align with data[j],\n",
        "- Load the top-100 token predictions for both clean and intervened.\n",
        "\n",
        "3. Match Tokens to Result Variants\n",
        "- variant_token_map = { \"sbb\": \"773\", ... }\n",
        "- For each run (clean/intervened) and each variant (bbb, sbb, etc.):\n",
        "- Match if the predicted token matches a known variant result token.\n",
        "- If matched, add its probability to the accumulator and increment the count.\n",
        "\n",
        "\n",
        "4. Compute Averages\n",
        "5. Save Results to JSON\n",
        "\n",
        "##  Expected Outcome\n",
        "\n",
        "If the digit circuit interventions work:\n",
        "\n",
        "The target variant's probability should increase (e.g., sbb for hundreds-digit intervention),\n",
        "The default variant (bbb) should decrease,\n",
        "Other variants should remain relatively stable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6r3yhnLRou_",
        "outputId": "cec0fd06-36fe-495f-e539-1cc671f9c1e7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "\n",
        "variant_labels = [\"bbb\", \"bbs\", \"bsb\", \"bss\", \"sbb\", \"sbs\", \"ssb\", \"sss\"]\n",
        "folder_path = \"Interventions/\"\n",
        "\n",
        "# Initialize accumulators: sums and counts for each run and variant label\n",
        "accumulated_probs = {\n",
        "    \"clean\": {label: 0.0 for label in variant_labels},\n",
        "    \"intervened\": {label: 0.0 for label in variant_labels}\n",
        "}\n",
        "counts = {\n",
        "    \"clean\": {label: 0 for label in variant_labels},\n",
        "    \"intervened\": {label: 0 for label in variant_labels}\n",
        "}\n",
        "\n",
        "# Get sorted CSV files\n",
        "csv_files = [f for f in os.listdir(folder_path) if re.match(r\"intervention_.*_(\\d+)\\.csv\", f)]\n",
        "csv_files.sort(key=lambda x: int(re.search(r\"_(\\d+)\", x).group(1)))\n",
        "\n",
        "for file_name in csv_files:\n",
        "    index_match = re.search(r\"_(\\d+)\\.csv$\", file_name)\n",
        "    i = int(index_match.group(1)) if index_match else None\n",
        "    if i is None:\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing example {i} from file {file_name}\")\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Map variant labels to target tokens from your loaded `data`\n",
        "    variant_token_map = {k: str(v) for k, v in data[i][\"result_variants\"].items()}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        run_type = row[\"run\"]  # \"clean\" or \"intervened\"\n",
        "        try:\n",
        "            token_probs = ast.literal_eval(row[\"top_100\"])\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing token probs in {file_name}, run={run_type}: {e}\")\n",
        "            continue\n",
        "\n",
        "        for variant_label, target_token in variant_token_map.items():\n",
        "            for entry in token_probs:\n",
        "                if entry[\"token\"] == target_token:\n",
        "                    prob = entry[\"prob\"]\n",
        "                    accumulated_probs[run_type][variant_label] += prob\n",
        "                    counts[run_type][variant_label] += 1\n",
        "\n",
        "# Compute averages over all examples and all files\n",
        "averages = {\n",
        "    run_type: {\n",
        "        label: (accumulated_probs[run_type][label] / counts[run_type][label]) if counts[run_type][label] > 0 else 0\n",
        "        for label in variant_labels\n",
        "    }\n",
        "    for run_type in [\"clean\", \"intervened\"]\n",
        "}\n",
        "\n",
        "# Save averages to JSON\n",
        "output_file = \"average_probabilities.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(averages, f, indent=4)\n",
        "\n",
        "print(\"Averages computed and saved to\", output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBVJb4Q6RvHe"
      },
      "source": [
        "#  Visualizing Intervention Effects on Digit Result Variants\n",
        "\n",
        "This visualization compares:\n",
        "- The **average predicted probability** of each **result variant** (e.g., `\"bbb\"`, `\"sbb\"`, etc.)\n",
        "- Across two conditions:\n",
        "  - `Clean` (no intervention)\n",
        "  - `Intervened` (digit-circuit intervention applied)\n",
        "\n",
        "Additionally, the plot includes a **difference bar** showing how each variant's probability **shifted** due to the intervention.\n",
        "\n",
        "This replicates the core idea in **Table 2** of the paper and gives a clear visual insight into the **causal specificity** of the digit circuits.\n",
        "\n",
        "---\n",
        "\n",
        "##  What‚Äôs Being Visualized?\n",
        "\n",
        "- `bbb`: Model predicts base result.\n",
        "- `sbb`, `bsb`, `bbs`: Only one digit comes from the source, others from base.\n",
        "- `sss`: Fully source result.\n",
        "\n",
        "Expected outcomes:\n",
        "- Large **drop** in `bbb` (baseline result),\n",
        "- **Increase** in a targeted variant (e.g., `sbb` if hundreds digit was intervened),\n",
        "- Minimal change in other variants.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "vXWGFMQXRwq2",
        "outputId": "8b546b1c-b903-4df7-bd2d-fc8dc0e8b610"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `averages` dict is computed as before:\n",
        "# averages = {\n",
        "#   \"clean\": {...},\n",
        "#   \"intervened\": {...}\n",
        "# }\n",
        "\n",
        "variant_labels = list(averages[\"clean\"].keys())\n",
        "\n",
        "clean_vals = [averages[\"clean\"][label] for label in variant_labels]\n",
        "intervened_vals = [averages[\"intervened\"][label] for label in variant_labels]\n",
        "diff_vals = [i - c for i, c in zip(intervened_vals, clean_vals)]\n",
        "\n",
        "x = np.arange(len(variant_labels))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "bars1 = ax.bar(x - width, clean_vals, width, label='Clean', color='tab:blue')\n",
        "bars2 = ax.bar(x, intervened_vals, width, label='Intervened', color='tab:orange')\n",
        "bars3 = ax.bar(x + width, diff_vals, width, label='Difference (Clean - Intervened)', color='tab:green')\n",
        "\n",
        "ax.set_ylabel('Average Probability')\n",
        "ax.set_title('Average Probabilities per Variant Label')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(variant_labels)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttJlKtm9Ry8G"
      },
      "source": [
        "#  Flip Rate Evaluation for Digit-Circuit Interventions\n",
        "\n",
        "This script computes the **flip rate** ‚Äî the fraction of test cases where an intervention successfully causes the model to change its top predicted result **from the default `bbb`** (base-base-base) **to the expected variant** (e.g., `bbs`, `bsb`, or `sbb` depending on the digit position).\n",
        "\n",
        "This replicates the metric reported in **Table 3** of the paper:  \n",
        "_\"Flip rate from bbb to the intended digit-specific result variant...\"_\n",
        "\n",
        "---\n",
        "\n",
        "##  Purpose\n",
        "\n",
        "- To measure whether digit-position-specific MLP interventions cause the **target digit** to flip to the desired source value, while **leaving the other digits intact**.\n",
        "- This provides **causal evidence** that digit circuits are:\n",
        "  - Modular,\n",
        "  - Selective,\n",
        "  - Functionally specific to their digit.\n",
        "\n",
        "---\n",
        "\n",
        "##  Setup\n",
        "\n",
        "Before running this:\n",
        "- `csv_files`: list of per-example `.csv` result files from prior intervention experiments.\n",
        "- `data`: loaded from the JSON intervention dataset (contains `result_variants` per example).\n",
        "- `label`: must be one of `\"unit\"`, `\"tenth\"`, or `\"hundredth\"`.\n",
        "\n",
        "The label determines the **expected flip target**:\n",
        "```python\n",
        "expected_variant_map = {\n",
        "    \"unit\": \"bbs\",         # Only unit digit changed\n",
        "    \"tenth\": \"bsb\",        # Only tens digit changed\n",
        "    \"hundredth\": \"sbb\"     # Only hundreds digit changed\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "The \"flip\" is counted only when the clean prediction is the unaltered base result (bbb) and the intervention successfully flips only the target digit to match the source (e.g., sbb for hundreds circuit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARa_JDyRR0Qv",
        "outputId": "dab330fb-6966-4f43-ffa6-c03c7e1fae13"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ast\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "import sys\n",
        "\n",
        "# Flip rate calculation\n",
        "expected_variant_map = {\n",
        "    \"unit\": \"bbs\",\n",
        "    \"tenth\": \"bsb\",\n",
        "    \"hundredth\": \"sbb\"\n",
        "}\n",
        "\n",
        "# Use your current label to find the expected variant\n",
        "expected_variant = expected_variant_map[label]  # 'label' must be defined in your loop or global scope\n",
        "\n",
        "flip_count = 0\n",
        "total_count = 0\n",
        "\n",
        "for file_name in csv_files:\n",
        "    index_match = re.search(r\"_(\\d+)\\.csv$\", file_name)\n",
        "    i = int(index_match.group(1)) if index_match else None\n",
        "    if i is None:\n",
        "        continue\n",
        "\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Get token mapping for this datapoint\n",
        "    variant_token_map = {k: str(v) for k, v in data[i][\"result_variants\"].items()}\n",
        "\n",
        "    # Dictionary to store best variant per run\n",
        "    best_variant = {}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        run_type = row[\"run\"]\n",
        "        try:\n",
        "            token_probs = ast.literal_eval(row[\"top_100\"])\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing token probs in {file_name}, run={run_type}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Find the best matching variant for this run\n",
        "        highest_prob = -1\n",
        "        predicted_variant = None\n",
        "\n",
        "        for variant_label, token in variant_token_map.items():\n",
        "            for entry in token_probs:\n",
        "                if entry[\"token\"] == token:\n",
        "                    if entry[\"prob\"] > highest_prob:\n",
        "                        highest_prob = entry[\"prob\"]\n",
        "                        predicted_variant = variant_label\n",
        "\n",
        "        best_variant[run_type] = predicted_variant\n",
        "\n",
        "    # Count flip: clean was bbb, intervened is expected variant\n",
        "    if best_variant.get(\"clean\") == \"bbb\" and best_variant.get(\"intervened\") == expected_variant:\n",
        "        flip_count += 1\n",
        "\n",
        "    total_count += 1\n",
        "\n",
        "flip_rate = flip_count / total_count if total_count > 0 else 0\n",
        "print(f\"\\n Flip Rate (from 'bbb' ‚Üí '{expected_variant}') = {flip_rate:.3f} over {total_count} examples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Flip Rate (from 'bbb' ‚Üí 'sbb') = 0.605 over 200 examples.\n",
        "This means:\n",
        "\n",
        "In 60.5% of test cases,\n",
        "The model switched from predicting the original result (bbb) to the correct variant for the digit being intervened on (sbb),\n",
        "Demonstrating successful digit-specific control."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e6c85bb6afa446e8c22b9bdecf9ebac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6cd96f2861df485c98963cee8fd11f9f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_294edc2636974381973a4981ca576e96",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "11644d5a8dbb4bd8a17cee2967f09c44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd8359385d4473b9249736a61dbc9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_34a5cea0e4f344ee999db2d8b94023ae",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67b063795012434ca84fda35af94a22f",
            "tabbable": null,
            "tooltip": null,
            "value": 4
          }
        },
        "294edc2636974381973a4981ca576e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "34a5cea0e4f344ee999db2d8b94023ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af381af35af4fe1a99c1a827ce069ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_11644d5a8dbb4bd8a17cee2967f09c44",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c69045c248594ea594850243be21de93",
            "tabbable": null,
            "tooltip": null,
            "value": "‚Äá4/4‚Äá[00:03&lt;00:00,‚Äá‚Äá1.27it/s]"
          }
        },
        "67b063795012434ca84fda35af94a22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cd96f2861df485c98963cee8fd11f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69045c248594ea594850243be21de93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e77b709fd4c04e1aa8162558af5b40fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed08da4944744403baedc3abacf26a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e6c85bb6afa446e8c22b9bdecf9ebac",
              "IPY_MODEL_1fd8359385d4473b9249736a61dbc9ef",
              "IPY_MODEL_4af381af35af4fe1a99c1a827ce069ef"
            ],
            "layout": "IPY_MODEL_e77b709fd4c04e1aa8162558af5b40fa",
            "tabbable": null,
            "tooltip": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
