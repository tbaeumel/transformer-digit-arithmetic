{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIztQfmuPlzv"
      },
      "source": [
        "Get the data from the repo -> anonymize!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeyBSXiAPlTn",
        "outputId": "03e4105e-ac4f-4689-bd7f-228d715deea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'transformer-digit-arithmetic'...\n",
            "remote: Enumerating objects: 689, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 689 (delta 10), reused 8 (delta 8), pack-reused 672 (from 5)\u001b[K\n",
            "Receiving objects: 100% (689/689), 42.75 MiB | 23.89 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tbaeumel/transformer-digit-arithmetic.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHeK7njlbLwe",
        "outputId": "e6268c0e-0398-4624-9f96-7ec5a7b9e005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jul 28 11:09:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   76C    P0             37W /   72W |   15635MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1j_pJjQPSh1",
        "outputId": "0fc1d8ff-c3d0-4079-de22-5382b2164b91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/transformer-digit-arithmetic/transformer-digit-arithmetic\n"
          ]
        }
      ],
      "source": [
        "%cd transformer-digit-arithmetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi4rRDHKaLOi"
      },
      "source": [
        "Get pyvene\n",
        "Olmo2 was not in pyvene - i wrote an extension so that olmo2 can be an intervenable model.\n",
        " has to be anonymized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijicRAr8pFiK",
        "outputId": "21922c5f-9995-438f-dd29-15a3e61a1555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tbaeumel/pyvene\n",
            "  Cloning https://github.com/tbaeumel/pyvene to /tmp/pip-req-build-g9c7854c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tbaeumel/pyvene /tmp/pip-req-build-g9c7854c\n",
            "  Resolved https://github.com/tbaeumel/pyvene to commit e9085b6d207d5790146921d02a8af4859406c9ea\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate>=0.34.2 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (1.9.0)\n",
            "Requirement already satisfied: datasets>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (4.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (0.33.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.1 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (8.1.7)\n",
            "Requirement already satisfied: matplotlib>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (3.10.0)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (2.0.2)\n",
            "Requirement already satisfied: plotnine>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (0.14.5)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (5.29.5)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (0.2.0)\n",
            "Requirement already satisfied: tokenizers>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (0.21.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.45.1 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.8) (4.53.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.8) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.8) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.8) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.8) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.8) (0.70.16)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->pyvene==0.1.8) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->pyvene==0.1.8) (1.1.5)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.8) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.8) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.8) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.8) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.8) (3.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.8) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.8) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.8) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.8) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.8) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.8) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.8) (2.9.0.post0)\n",
            "Requirement already satisfied: mizani~=0.13.0 in /usr/local/lib/python3.11/dist-packages (from plotnine>=0.12.4->pyvene==0.1.8) (0.13.5)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from plotnine>=0.12.4->pyvene==0.1.8) (1.16.0)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from plotnine>=0.12.4->pyvene==0.1.8) (0.14.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->pyvene==0.1.8) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.1->pyvene==0.1.8) (2024.11.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (3.12.14)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (4.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.1->pyvene==0.1.8) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.1->pyvene==0.1.8) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.4->pyvene==0.1.8) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.8) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.8) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.8) (2025.7.14)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->plotnine>=0.12.4->pyvene==0.1.8) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyvene==0.1.8) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.1->pyvene==0.1.8) (1.20.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.8) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# pip uninstall -y pyvene  # pyvene has to be uninstalled if a standard version is currently installed\n",
        "# pip install pyvene\n",
        "!pip install git+https://github.com/tbaeumel/pyvene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQSGxa7hQcKu",
        "outputId": "3c1eaf38-2d37-4e79-83b2-c171d120fe65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
          ]
        }
      ],
      "source": [
        "import pyvene as pv\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from pyvene import embed_to_distrib, top_vals, format_token\n",
        "from pyvene import (\n",
        "    ZeroIntervention,\n",
        "    IntervenableModel,\n",
        "    VanillaIntervention, Intervention,\n",
        "    RepresentationConfig,\n",
        "    IntervenableConfig,\n",
        "    ConstantSourceIntervention,\n",
        "    LocalistRepresentationIntervention\n",
        ")\n",
        "from huggingface_hub import login\n",
        "import re\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import transformers\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93z_4vN6QivG"
      },
      "source": [
        "## Load model\n",
        "\n",
        "Llama 70B wont work on colab\n",
        "\n",
        "llama 8b and olmo 2 7b will work on l4 or a100\n",
        "\n",
        "people have to login with their huggingface key to get access to the llama models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DtGz_kwgQjxm"
      },
      "outputs": [],
      "source": [
        "# Login to Huggingface to get access to model parameters\n",
        "# Paste your token here\n",
        "login('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_VmQMDbeQxN2"
      },
      "outputs": [],
      "source": [
        "# choose your model\n",
        "model_name = \"Llama-3-8B\" # Llama-3-70B # Olmo-2-7B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "ed08da4944744403baedc3abacf26a69",
            "0e6c85bb6afa446e8c22b9bdecf9ebac",
            "1fd8359385d4473b9249736a61dbc9ef",
            "4af381af35af4fe1a99c1a827ce069ef",
            "e77b709fd4c04e1aa8162558af5b40fa",
            "6cd96f2861df485c98963cee8fd11f9f",
            "294edc2636974381973a4981ca576e96",
            "34a5cea0e4f344ee999db2d8b94023ae",
            "67b063795012434ca84fda35af94a22f",
            "11644d5a8dbb4bd8a17cee2967f09c44",
            "c69045c248594ea594850243be21de93"
          ]
        },
        "id": "gCBzhTaDQx8O",
        "outputId": "2452d127-9160-4afb-dc3f-bc6f1530a043"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed08da4944744403baedc3abacf26a69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Using GPU\n"
          ]
        }
      ],
      "source": [
        "models = {\"Llama-3-8B\": \"meta-llama/Meta-Llama-3-8B\", \"Llama-3-70B\": \"meta-llama/Meta-Llama-3-70B\", \"Olmo-2-7B\": \"allenai/OLMo-2-1124-7B\" }\n",
        "\n",
        "# Set parameters\n",
        "params = {\n",
        "    'model_name': models[model_name],\n",
        "    'device': \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(params['model_name'])\n",
        "model = AutoModelForCausalLM.from_pretrained(params['model_name'], torch_dtype=torch.float16).to(params['device'])\n",
        "\n",
        "# Confirm device\n",
        "print(f\"Using device: {params['device']}\")\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Using GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbk3s-9eQ8OR"
      },
      "source": [
        "# Digit circuit Intervention\n",
        "\n",
        "Choose:\n",
        "- thresholds (pre computed using Fisher scores)\n",
        "- digit position (hundredth,tenth,unit)\n",
        "- task (operator) (+,-)\n",
        "- operand (which intervention dataset) (op1 + op2 = ..) two variation either fix op1 or op2\n",
        "\n",
        "this can be changed to standard values for the thresholds and layers (see paper Section X), so that based on model and digti position the best threshold is chosen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0xUTzMfLQ9tP"
      },
      "outputs": [],
      "source": [
        "# labels\n",
        "label = \"hundredth\" # \"tenth\" # \"unit\"\n",
        "# task (operator)\n",
        "task = \"addition\" # \"subtraction\"\n",
        "# which oeprand\n",
        "operand = \"op1\" # \"op2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lGuiGwxufMS",
        "outputId": "ff25d60f-7f6f-4f30-f825-2daf39ff0683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer_set: [16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "threshold: 0.8\n"
          ]
        }
      ],
      "source": [
        "# Load the JSON file\n",
        "input_file = f\"Intervention_Data/intervention_data_{task}_{operand}.json\"\n",
        "with open(input_file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# layer sets to intervene on based on model, task, and operand\n",
        "# TODO do this elegantly\n",
        "\n",
        "with open(f\"intervene_layers.json\", \"r\") as f:\n",
        "    layer_sets = json.load(f)\n",
        "layer_set = layer_sets[model_name][task][operand] ## return layers set for the corresponding experiment\n",
        "\n",
        "\n",
        "with open(f\"fisher_scores_threshold_map.json\", \"r\") as f:\n",
        "    threshold_map = json.load(f)\n",
        "threshold = threshold_map[model_name][task][operand][label] ## return threshold float for the corresponding experiment\n",
        "\n",
        "print(\"layer_set:\",layer_set)\n",
        "print(\"threshold:\",threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx2IAdTqRZnu"
      },
      "source": [
        "Extract the MLP dimensions that have a fisher score above the chosen threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGKn-ixIRTaF",
        "outputId": "360d0637-8500-4a5a-bb5d-bb53e047089b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{16: [1, 4, 5, 6, 7, 22, 34, 42, 58, 63, 70, 71, 77, 82, 92, 102, 103, 133, 144, 147, 150, 152, 161, 165, 167, 172, 173, 186, 195, 199, 203, 206, 210, 213, 214, 223, 232, 235, 236, 245, 253, 265, 267, 271, 272, 283, 285, 289, 290, 294, 302, 304, 305, 306, 307, 321, 334, 336, 342, 344, 348, 355, 359, 363, 378, 401, 406, 413, 416, 440, 446, 450, 452, 455, 460, 475, 477, 481, 486, 488, 508, 516, 517, 518, 521, 527, 529, 541, 543, 545, 550, 555, 558, 569, 572, 576, 579, 590, 592, 596, 617, 620, 626, 638, 643, 649, 666, 670, 675, 677, 708, 717, 728, 743, 755, 758, 761, 762, 775, 793, 802, 804, 806, 810, 824, 834, 852, 853, 866, 867, 870, 880, 908, 912, 921, 934, 935, 938, 943, 946, 974, 982, 984, 985, 986, 989, 994, 1017, 1018, 1022, 1031, 1041, 1059, 1062, 1064, 1066, 1067, 1077, 1079, 1087, 1104, 1106, 1130, 1146, 1147, 1153, 1158, 1167, 1169, 1173, 1188, 1191, 1215, 1216, 1219, 1225, 1227, 1228, 1233, 1236, 1238, 1253, 1257, 1258, 1259, 1265, 1270, 1273, 1277, 1280, 1287, 1303, 1305, 1310, 1318, 1319, 1323, 1326, 1330, 1360, 1362, 1363, 1366, 1369, 1398, 1408, 1419, 1421, 1424, 1425, 1440, 1446, 1457, 1465, 1466, 1468, 1483, 1510, 1519, 1534, 1536, 1537, 1543, 1554, 1561, 1570, 1585, 1593, 1596, 1597, 1600, 1604, 1612, 1613, 1624, 1631, 1636, 1640, 1643, 1644, 1657, 1662, 1673, 1682, 1701, 1714, 1716, 1720, 1732, 1739, 1743, 1746, 1753, 1762, 1800, 1803, 1804, 1807, 1809, 1815, 1825, 1835, 1837, 1842, 1844, 1856, 1867, 1877, 1878, 1881, 1906, 1914, 1917, 1921, 1930, 1937, 1939, 1945, 1948, 1956, 1961, 1965, 1972, 1979, 1987, 1994, 2002, 2005, 2025, 2040, 2041, 2051, 2052, 2060, 2083, 2100, 2114, 2134, 2161, 2162, 2169, 2174, 2183, 2184, 2194, 2199, 2218, 2220, 2222, 2223, 2227, 2228, 2230, 2243, 2260, 2261, 2265, 2266, 2271, 2276, 2278, 2291, 2292, 2296, 2304, 2306, 2307, 2317, 2322, 2323, 2327, 2334, 2336, 2338, 2358, 2360, 2365, 2366, 2369, 2372, 2379, 2381, 2384, 2385, 2393, 2394, 2399, 2404, 2412, 2419, 2423, 2426, 2430, 2439, 2444, 2451, 2454, 2457, 2459, 2462, 2475, 2498, 2499, 2510, 2517, 2522, 2524, 2549, 2561, 2568, 2571, 2581, 2583, 2593, 2598, 2613, 2621, 2622, 2625, 2628, 2648, 2652, 2658, 2691, 2696, 2698, 2709, 2710, 2716, 2718, 2723, 2726, 2736, 2752, 2791, 2792, 2796, 2798, 2801, 2829, 2831, 2844, 2845, 2846, 2848, 2853, 2856, 2862, 2864, 2869, 2892, 2901, 2910, 2919, 2922, 2932, 2947, 2949, 2956, 2960, 2961, 2969, 2971, 2978, 2993, 2994, 2998, 3006, 3012, 3015, 3017, 3020, 3023, 3025, 3028, 3047, 3056, 3057, 3058, 3067, 3071, 3084, 3094, 3111, 3123, 3132, 3136, 3139, 3147, 3169, 3191, 3194, 3197, 3212, 3214, 3220, 3222, 3244, 3258, 3260, 3261, 3263, 3266, 3268, 3275, 3279, 3286, 3315, 3317, 3323, 3335, 3356, 3385, 3391, 3399, 3409, 3422, 3423, 3435, 3449, 3456, 3460, 3462, 3468, 3470, 3471, 3480, 3492, 3497, 3500, 3516, 3519, 3527, 3532, 3554, 3565, 3572, 3580, 3581, 3604, 3615, 3618, 3620, 3626, 3632, 3635, 3651, 3653, 3665, 3668, 3674, 3688, 3690, 3693, 3694, 3705, 3723, 3726, 3735, 3743, 3759, 3760, 3761, 3769, 3770, 3772, 3777, 3781, 3784, 3786, 3802, 3809, 3814, 3818, 3834, 3839, 3847, 3852, 3861, 3863, 3898, 3903, 3905, 3906, 3909, 3934, 3935, 3942, 3943, 3947, 3950, 3957, 3984, 3991, 3996, 3997, 4004, 4007, 4012, 4025, 4031, 4033, 4037, 4049, 4056, 4062, 4072, 4080, 4088, 4095], 17: [11, 14, 19, 24, 31, 60, 67, 70, 74, 75, 79, 80, 81, 83, 89, 106, 107, 118, 119, 120, 128, 133, 150, 178, 198, 219, 257, 258, 273, 277, 289, 292, 297, 304, 305, 315, 321, 343, 364, 369, 383, 400, 414, 419, 420, 433, 440, 451, 452, 458, 459, 466, 479, 482, 483, 491, 500, 506, 514, 517, 533, 534, 539, 540, 553, 557, 563, 571, 572, 573, 575, 581, 589, 590, 591, 593, 600, 602, 615, 635, 642, 643, 646, 655, 659, 669, 676, 681, 682, 686, 687, 704, 730, 731, 734, 735, 754, 756, 757, 758, 760, 769, 771, 773, 778, 792, 799, 801, 824, 825, 836, 837, 858, 865, 907, 909, 913, 914, 918, 921, 926, 932, 943, 944, 960, 961, 984, 998, 1010, 1064, 1068, 1070, 1071, 1078, 1081, 1104, 1111, 1117, 1121, 1129, 1131, 1143, 1165, 1167, 1182, 1184, 1186, 1191, 1198, 1204, 1214, 1215, 1219, 1221, 1227, 1231, 1244, 1247, 1249, 1250, 1255, 1266, 1276, 1282, 1295, 1298, 1326, 1342, 1364, 1373, 1377, 1387, 1390, 1396, 1399, 1400, 1402, 1405, 1421, 1431, 1447, 1451, 1457, 1462, 1496, 1505, 1514, 1530, 1542, 1550, 1551, 1562, 1570, 1574, 1578, 1592, 1599, 1605, 1608, 1618, 1623, 1633, 1635, 1638, 1644, 1646, 1649, 1655, 1678, 1686, 1698, 1701, 1716, 1736, 1740, 1747, 1751, 1760, 1764, 1775, 1792, 1795, 1799, 1800, 1821, 1833, 1835, 1852, 1866, 1876, 1878, 1880, 1886, 1895, 1918, 1919, 1955, 1961, 1962, 1964, 1972, 1977, 1978, 1999, 2000, 2020, 2026, 2034, 2058, 2061, 2065, 2071, 2072, 2078, 2086, 2091, 2096, 2098, 2099, 2122, 2132, 2140, 2146, 2147, 2151, 2165, 2170, 2176, 2190, 2202, 2214, 2223, 2232, 2240, 2243, 2244, 2260, 2262, 2266, 2286, 2292, 2308, 2315, 2326, 2330, 2347, 2348, 2355, 2363, 2387, 2400, 2402, 2415, 2417, 2428, 2431, 2450, 2454, 2457, 2474, 2477, 2499, 2509, 2522, 2524, 2533, 2536, 2546, 2549, 2558, 2567, 2584, 2587, 2590, 2595, 2598, 2602, 2606, 2609, 2616, 2626, 2629, 2640, 2644, 2654, 2679, 2680, 2687, 2706, 2709, 2710, 2733, 2745, 2750, 2756, 2781, 2806, 2814, 2824, 2831, 2850, 2853, 2855, 2857, 2861, 2863, 2872, 2888, 2907, 2917, 2920, 2926, 2927, 2931, 2966, 2974, 2975, 2978, 2984, 2985, 2990, 2991, 2994, 3026, 3029, 3037, 3057, 3062, 3066, 3068, 3083, 3103, 3105, 3108, 3110, 3137, 3140, 3142, 3147, 3157, 3158, 3159, 3168, 3184, 3192, 3196, 3200, 3201, 3206, 3207, 3210, 3248, 3256, 3261, 3270, 3272, 3276, 3292, 3295, 3305, 3309, 3324, 3330, 3340, 3342, 3344, 3350, 3351, 3357, 3358, 3375, 3427, 3432, 3435, 3445, 3446, 3450, 3463, 3465, 3467, 3485, 3490, 3500, 3506, 3512, 3522, 3538, 3540, 3548, 3561, 3566, 3569, 3575, 3579, 3580, 3585, 3588, 3590, 3599, 3623, 3632, 3646, 3650, 3658, 3661, 3674, 3692, 3704, 3713, 3717, 3722, 3727, 3728, 3735, 3736, 3758, 3775, 3777, 3779, 3783, 3792, 3827, 3834, 3838, 3849, 3855, 3862, 3872, 3876, 3901, 3903, 3907, 3909, 3910, 3912, 3918, 3922, 3923, 3931, 3954, 3967, 3980, 3985, 3990, 3999, 4004, 4015, 4049, 4051, 4054, 4057, 4059, 4065, 4069, 4079], 18: [2, 7, 14, 18, 19, 21, 22, 30, 34, 35, 43, 53, 54, 59, 61, 77, 79, 83, 84, 86, 89, 92, 98, 100, 108, 113, 114, 116, 118, 124, 131, 134, 138, 141, 142, 145, 148, 150, 153, 159, 160, 161, 163, 174, 175, 181, 186, 187, 192, 194, 196, 199, 203, 204, 210, 211, 215, 217, 219, 223, 229, 230, 232, 233, 236, 237, 240, 247, 250, 253, 255, 256, 266, 267, 271, 273, 274, 277, 283, 284, 287, 292, 297, 299, 300, 303, 304, 311, 315, 321, 324, 326, 333, 334, 335, 344, 352, 356, 357, 358, 361, 365, 371, 374, 375, 376, 377, 379, 381, 382, 389, 390, 391, 392, 393, 397, 401, 402, 404, 415, 420, 423, 424, 427, 428, 429, 430, 431, 435, 440, 442, 443, 444, 446, 447, 448, 450, 451, 452, 460, 463, 466, 468, 469, 472, 475, 481, 483, 489, 491, 492, 493, 500, 502, 505, 508, 509, 513, 524, 525, 527, 530, 534, 537, 539, 541, 542, 546, 549, 552, 569, 573, 577, 580, 581, 583, 585, 586, 587, 589, 591, 592, 594, 595, 596, 599, 600, 602, 603, 611, 615, 617, 619, 622, 623, 624, 626, 634, 644, 646, 656, 659, 660, 663, 664, 665, 666, 673, 678, 699, 706, 707, 708, 711, 712, 714, 715, 717, 725, 726, 731, 734, 735, 742, 744, 748, 755, 756, 758, 775, 777, 778, 784, 786, 787, 792, 793, 798, 812, 815, 819, 821, 835, 839, 841, 848, 849, 858, 868, 870, 871, 873, 874, 876, 888, 891, 893, 894, 895, 896, 899, 902, 905, 908, 913, 915, 916, 921, 923, 924, 925, 926, 928, 932, 934, 935, 938, 940, 941, 943, 944, 947, 950, 953, 957, 959, 960, 964, 969, 977, 983, 984, 992, 1003, 1007, 1008, 1010, 1013, 1019, 1021, 1023, 1025, 1026, 1032, 1033, 1042, 1044, 1050, 1053, 1054, 1061, 1062, 1063, 1064, 1069, 1071, 1073, 1076, 1079, 1081, 1085, 1087, 1089, 1091, 1098, 1100, 1102, 1116, 1118, 1119, 1121, 1123, 1124, 1126, 1134, 1136, 1142, 1144, 1149, 1155, 1157, 1166, 1168, 1169, 1175, 1178, 1179, 1181, 1182, 1183, 1193, 1195, 1200, 1203, 1208, 1211, 1218, 1220, 1222, 1226, 1227, 1230, 1231, 1234, 1236, 1240, 1244, 1248, 1249, 1252, 1255, 1257, 1260, 1279, 1282, 1289, 1297, 1300, 1303, 1304, 1307, 1308, 1314, 1319, 1323, 1324, 1330, 1335, 1338, 1343, 1345, 1346, 1347, 1351, 1354, 1357, 1361, 1362, 1365, 1369, 1372, 1374, 1380, 1384, 1392, 1393, 1397, 1398, 1401, 1410, 1413, 1418, 1423, 1428, 1429, 1440, 1443, 1444, 1448, 1454, 1457, 1459, 1460, 1462, 1463, 1467, 1469, 1470, 1473, 1475, 1479, 1480, 1482, 1486, 1488, 1496, 1502, 1506, 1510, 1511, 1516, 1517, 1522, 1523, 1525, 1529, 1532, 1540, 1548, 1549, 1551, 1554, 1555, 1558, 1559, 1561, 1565, 1575, 1576, 1583, 1584, 1585, 1586, 1589, 1591, 1592, 1600, 1602, 1604, 1605, 1606, 1612, 1616, 1618, 1633, 1635, 1637, 1639, 1643, 1646, 1649, 1651, 1652, 1660, 1666, 1667, 1669, 1671, 1674, 1678, 1682, 1683, 1686, 1708, 1709, 1712, 1713, 1714, 1716, 1719, 1720, 1721, 1732, 1739, 1741, 1743, 1749, 1750, 1753, 1754, 1755, 1771, 1775, 1777, 1778, 1783, 1785, 1786, 1788, 1791, 1794, 1797, 1803, 1805, 1809, 1810, 1814, 1815, 1817, 1818, 1819, 1824, 1828, 1830, 1834, 1835, 1837, 1840, 1843, 1846, 1849, 1856, 1859, 1860, 1862, 1864, 1866, 1867, 1868, 1871, 1880, 1882, 1883, 1886, 1890, 1894, 1896, 1902, 1903, 1906, 1916, 1917, 1919, 1923, 1930, 1932, 1933, 1935, 1937, 1942, 1945, 1948, 1949, 1953, 1956, 1964, 1966, 1967, 1970, 1974, 1975, 1976, 1977, 1979, 1980, 1988, 1991, 1996, 1997, 2000, 2006, 2008, 2009, 2015, 2020, 2021, 2023, 2030, 2032, 2035, 2036, 2040, 2048, 2053, 2054, 2055, 2056, 2065, 2067, 2068, 2070, 2071, 2074, 2077, 2080, 2082, 2084, 2087, 2097, 2098, 2099, 2107, 2109, 2110, 2113, 2119, 2130, 2134, 2135, 2138, 2139, 2141, 2142, 2143, 2145, 2146, 2147, 2148, 2167, 2172, 2175, 2176, 2177, 2181, 2184, 2187, 2189, 2194, 2195, 2197, 2200, 2202, 2208, 2209, 2210, 2214, 2215, 2221, 2229, 2233, 2236, 2237, 2243, 2244, 2246, 2248, 2252, 2271, 2275, 2279, 2280, 2292, 2295, 2297, 2299, 2306, 2308, 2312, 2314, 2315, 2330, 2331, 2339, 2341, 2342, 2344, 2345, 2349, 2353, 2358, 2360, 2361, 2365, 2369, 2371, 2373, 2378, 2385, 2386, 2387, 2390, 2391, 2401, 2402, 2403, 2407, 2413, 2417, 2418, 2420, 2422, 2423, 2431, 2433, 2434, 2438, 2448, 2449, 2450, 2452, 2456, 2457, 2466, 2469, 2471, 2473, 2477, 2486, 2489, 2492, 2493, 2497, 2498, 2503, 2504, 2510, 2514, 2516, 2519, 2520, 2525, 2527, 2540, 2541, 2561, 2565, 2568, 2576, 2577, 2581, 2583, 2584, 2585, 2587, 2589, 2590, 2594, 2595, 2596, 2597, 2601, 2609, 2611, 2613, 2614, 2615, 2619, 2628, 2629, 2633, 2634, 2636, 2644, 2645, 2647, 2651, 2657, 2660, 2662, 2663, 2666, 2668, 2676, 2680, 2682, 2688, 2696, 2697, 2701, 2705, 2707, 2710, 2711, 2722, 2724, 2735, 2739, 2740, 2741, 2743, 2749, 2752, 2760, 2768, 2769, 2777, 2779, 2781, 2783, 2792, 2794, 2799, 2806, 2811, 2812, 2820, 2822, 2829, 2830, 2835, 2836, 2839, 2843, 2847, 2853, 2854, 2867, 2868, 2888, 2890, 2898, 2900, 2901, 2904, 2905, 2906, 2910, 2912, 2927, 2929, 2930, 2932, 2934, 2938, 2939, 2942, 2943, 2952, 2956, 2967, 2971, 2974, 2975, 2977, 2980, 2983, 2984, 2986, 2988, 2990, 2991, 2992, 2994, 2998, 2999, 3002, 3009, 3013, 3016, 3019, 3022, 3025, 3026, 3027, 3028, 3029, 3030, 3032, 3034, 3035, 3037, 3039, 3041, 3045, 3052, 3054, 3068, 3070, 3077, 3079, 3080, 3082, 3084, 3093, 3094, 3097, 3102, 3103, 3105, 3108, 3109, 3112, 3113, 3116, 3117, 3125, 3129, 3134, 3139, 3143, 3144, 3148, 3153, 3154, 3160, 3161, 3168, 3172, 3173, 3175, 3177, 3183, 3185, 3188, 3192, 3197, 3199, 3201, 3202, 3213, 3214, 3215, 3216, 3222, 3226, 3229, 3230, 3232, 3239, 3240, 3241, 3242, 3244, 3250, 3251, 3252, 3253, 3260, 3261, 3263, 3265, 3270, 3273, 3276, 3280, 3284, 3285, 3287, 3288, 3289, 3290, 3291, 3294, 3296, 3298, 3299, 3302, 3308, 3309, 3315, 3317, 3318, 3320, 3322, 3324, 3326, 3333, 3341, 3343, 3344, 3350, 3351, 3358, 3359, 3362, 3365, 3370, 3378, 3388, 3395, 3396, 3398, 3400, 3402, 3410, 3414, 3416, 3418, 3423, 3426, 3427, 3431, 3437, 3438, 3444, 3445, 3446, 3448, 3449, 3456, 3459, 3460, 3462, 3469, 3471, 3472, 3474, 3477, 3478, 3480, 3481, 3488, 3489, 3491, 3495, 3498, 3499, 3500, 3505, 3506, 3507, 3511, 3512, 3516, 3520, 3523, 3529, 3535, 3542, 3548, 3552, 3554, 3556, 3568, 3570, 3571, 3577, 3578, 3579, 3581, 3582, 3583, 3585, 3589, 3597, 3598, 3602, 3603, 3607, 3611, 3615, 3616, 3619, 3623, 3630, 3631, 3637, 3639, 3641, 3642, 3643, 3651, 3654, 3661, 3662, 3663, 3664, 3670, 3671, 3672, 3674, 3687, 3688, 3691, 3694, 3699, 3700, 3702, 3703, 3704, 3706, 3710, 3711, 3712, 3719, 3720, 3722, 3723, 3728, 3731, 3733, 3734, 3735, 3739, 3742, 3747, 3751, 3752, 3757, 3758, 3759, 3760, 3761, 3763, 3766, 3767, 3769, 3774, 3779, 3781, 3782, 3783, 3784, 3787, 3790, 3791, 3792, 3794, 3797, 3802, 3804, 3809, 3815, 3819, 3824, 3826, 3828, 3834, 3841, 3848, 3851, 3853, 3854, 3856, 3863, 3865, 3867, 3868, 3872, 3873, 3874, 3875, 3876, 3880, 3883, 3886, 3888, 3890, 3891, 3897, 3898, 3901, 3907, 3910, 3911, 3912, 3914, 3922, 3923, 3924, 3929, 3930, 3936, 3937, 3939, 3945, 3951, 3953, 3954, 3961, 3962, 3970, 3974, 3977, 3978, 3979, 3982, 3986, 3990, 3993, 3997, 4000, 4002, 4003, 4004, 4007, 4011, 4012, 4015, 4016, 4031, 4034, 4035, 4036, 4037, 4039, 4045, 4051, 4054, 4058, 4060, 4064, 4066, 4068, 4071, 4078, 4080, 4081, 4083, 4084, 4088, 4090, 4091, 4095], 19: [0, 1, 4, 5, 6, 10, 11, 12, 13, 18, 21, 24, 25, 26, 28, 30, 31, 32, 34, 39, 41, 46, 47, 51, 57, 62, 71, 73, 75, 76, 77, 80, 88, 92, 94, 95, 97, 104, 108, 109, 110, 111, 113, 114, 115, 116, 119, 120, 121, 122, 124, 125, 130, 132, 133, 135, 137, 138, 139, 141, 142, 143, 145, 147, 148, 149, 150, 158, 159, 161, 164, 168, 173, 177, 178, 183, 185, 188, 202, 203, 205, 207, 211, 215, 220, 228, 232, 233, 234, 236, 237, 238, 244, 247, 250, 251, 252, 254, 255, 256, 257, 259, 263, 264, 265, 267, 270, 271, 273, 274, 275, 276, 277, 278, 280, 287, 288, 291, 293, 294, 295, 296, 297, 299, 302, 303, 305, 307, 309, 312, 313, 315, 316, 317, 319, 322, 323, 330, 331, 334, 336, 338, 340, 341, 342, 343, 344, 348, 350, 351, 352, 355, 356, 357, 363, 366, 367, 372, 375, 377, 382, 386, 387, 388, 389, 390, 393, 398, 401, 404, 405, 411, 414, 425, 428, 430, 432, 437, 439, 440, 441, 444, 445, 448, 451, 458, 462, 465, 468, 471, 475, 477, 482, 483, 484, 486, 488, 489, 491, 493, 494, 495, 496, 497, 499, 503, 504, 505, 512, 513, 514, 515, 520, 521, 524, 527, 534, 535, 544, 545, 546, 548, 553, 558, 564, 565, 568, 575, 577, 581, 585, 588, 589, 590, 592, 594, 599, 601, 602, 603, 608, 612, 613, 622, 626, 631, 632, 633, 634, 635, 638, 641, 645, 650, 652, 653, 654, 658, 661, 662, 666, 675, 676, 682, 683, 685, 687, 695, 696, 697, 698, 706, 707, 709, 712, 714, 715, 717, 718, 725, 728, 730, 731, 733, 736, 741, 743, 744, 745, 747, 749, 750, 752, 755, 756, 759, 760, 761, 777, 778, 782, 783, 788, 790, 791, 794, 797, 802, 806, 807, 809, 810, 812, 813, 815, 816, 821, 823, 825, 826, 829, 833, 835, 838, 840, 841, 842, 843, 844, 847, 851, 853, 856, 858, 862, 863, 865, 869, 871, 875, 876, 877, 880, 881, 884, 898, 907, 908, 910, 913, 915, 916, 919, 920, 922, 926, 932, 935, 937, 939, 940, 942, 946, 947, 949, 951, 953, 954, 955, 958, 959, 960, 961, 964, 966, 970, 973, 975, 976, 977, 981, 984, 989, 990, 991, 992, 997, 1000, 1001, 1004, 1005, 1009, 1011, 1012, 1013, 1015, 1016, 1019, 1021, 1022, 1025, 1026, 1029, 1032, 1035, 1037, 1038, 1041, 1042, 1044, 1045, 1046, 1047, 1049, 1053, 1058, 1061, 1062, 1066, 1068, 1069, 1073, 1075, 1079, 1080, 1081, 1084, 1087, 1091, 1097, 1101, 1102, 1103, 1104, 1105, 1109, 1110, 1112, 1123, 1128, 1129, 1130, 1133, 1134, 1136, 1137, 1138, 1140, 1143, 1144, 1147, 1148, 1151, 1164, 1166, 1168, 1172, 1174, 1176, 1180, 1185, 1187, 1188, 1192, 1193, 1194, 1195, 1197, 1198, 1202, 1203, 1208, 1212, 1216, 1217, 1218, 1223, 1224, 1225, 1227, 1231, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1245, 1246, 1247, 1248, 1250, 1252, 1253, 1255, 1260, 1261, 1264, 1266, 1269, 1270, 1271, 1275, 1276, 1277, 1278, 1281, 1282, 1285, 1287, 1290, 1291, 1296, 1297, 1298, 1301, 1303, 1305, 1311, 1313, 1317, 1320, 1322, 1325, 1327, 1329, 1331, 1337, 1340, 1341, 1343, 1345, 1349, 1351, 1356, 1374, 1375, 1376, 1379, 1381, 1385, 1389, 1390, 1391, 1395, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1410, 1412, 1416, 1419, 1421, 1422, 1423, 1425, 1427, 1429, 1436, 1440, 1442, 1443, 1447, 1450, 1452, 1455, 1458, 1459, 1460, 1464, 1465, 1467, 1468, 1473, 1474, 1476, 1477, 1478, 1480, 1481, 1489, 1492, 1493, 1496, 1505, 1507, 1514, 1515, 1518, 1520, 1521, 1522, 1524, 1525, 1526, 1529, 1530, 1533, 1535, 1536, 1543, 1544, 1550, 1551, 1553, 1558, 1560, 1561, 1562, 1563, 1568, 1569, 1570, 1571, 1578, 1579, 1584, 1586, 1588, 1592, 1594, 1596, 1597, 1599, 1600, 1601, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1611, 1614, 1621, 1623, 1626, 1627, 1628, 1630, 1632, 1636, 1639, 1642, 1643, 1644, 1649, 1654, 1657, 1667, 1669, 1670, 1672, 1673, 1675, 1676, 1680, 1681, 1685, 1686, 1690, 1691, 1692, 1693, 1695, 1696, 1697, 1698, 1702, 1705, 1706, 1708, 1709, 1713, 1715, 1717, 1718, 1720, 1721, 1722, 1723, 1725, 1738, 1742, 1743, 1749, 1750, 1753, 1760, 1761, 1768, 1769, 1770, 1771, 1775, 1780, 1781, 1786, 1787, 1792, 1793, 1795, 1796, 1798, 1799, 1804, 1806, 1808, 1809, 1812, 1823, 1824, 1825, 1826, 1828, 1829, 1830, 1831, 1833, 1834, 1842, 1845, 1849, 1850, 1854, 1856, 1860, 1866, 1869, 1874, 1891, 1892, 1895, 1897, 1905, 1909, 1910, 1915, 1921, 1923, 1925, 1928, 1930, 1933, 1944, 1948, 1949, 1950, 1954, 1955, 1960, 1963, 1967, 1969, 1971, 1972, 1979, 1981, 1983, 1991, 1996, 1999, 2001, 2003, 2011, 2017, 2018, 2019, 2021, 2023, 2030, 2035, 2037, 2038, 2040, 2043, 2049, 2052, 2054, 2055, 2056, 2058, 2062, 2067, 2077, 2081, 2082, 2084, 2086, 2092, 2095, 2100, 2102, 2106, 2108, 2111, 2114, 2115, 2116, 2117, 2120, 2123, 2126, 2128, 2130, 2132, 2136, 2138, 2139, 2140, 2141, 2145, 2149, 2154, 2155, 2161, 2163, 2164, 2182, 2187, 2191, 2193, 2195, 2196, 2198, 2201, 2204, 2206, 2214, 2215, 2218, 2224, 2227, 2228, 2230, 2233, 2234, 2242, 2244, 2250, 2251, 2252, 2253, 2254, 2256, 2258, 2262, 2268, 2274, 2278, 2282, 2283, 2285, 2286, 2287, 2290, 2292, 2293, 2295, 2298, 2300, 2301, 2302, 2304, 2311, 2312, 2315, 2320, 2326, 2328, 2329, 2330, 2331, 2332, 2334, 2335, 2336, 2339, 2340, 2341, 2343, 2344, 2347, 2358, 2359, 2361, 2362, 2364, 2365, 2369, 2370, 2374, 2377, 2378, 2379, 2380, 2381, 2383, 2386, 2387, 2388, 2390, 2397, 2401, 2402, 2405, 2409, 2411, 2412, 2413, 2419, 2420, 2421, 2429, 2431, 2432, 2435, 2437, 2439, 2443, 2448, 2449, 2451, 2453, 2462, 2469, 2475, 2480, 2481, 2485, 2486, 2488, 2495, 2497, 2501, 2502, 2503, 2505, 2506, 2507, 2510, 2511, 2513, 2517, 2519, 2520, 2522, 2523, 2525, 2528, 2529, 2530, 2532, 2533, 2534, 2536, 2540, 2543, 2544, 2549, 2553, 2555, 2560, 2562, 2564, 2569, 2570, 2572, 2573, 2577, 2578, 2579, 2582, 2583, 2587, 2589, 2591, 2592, 2594, 2595, 2598, 2600, 2602, 2604, 2605, 2609, 2610, 2611, 2613, 2614, 2618, 2619, 2624, 2629, 2630, 2631, 2637, 2641, 2642, 2643, 2644, 2647, 2649, 2650, 2652, 2654, 2658, 2666, 2667, 2668, 2672, 2674, 2676, 2677, 2678, 2683, 2684, 2686, 2687, 2691, 2693, 2694, 2695, 2699, 2700, 2703, 2709, 2710, 2716, 2717, 2720, 2721, 2722, 2724, 2725, 2728, 2730, 2733, 2735, 2737, 2740, 2743, 2753, 2755, 2758, 2759, 2760, 2762, 2765, 2766, 2767, 2770, 2771, 2773, 2774, 2776, 2779, 2780, 2782, 2785, 2791, 2792, 2793, 2794, 2795, 2797, 2804, 2826, 2828, 2832, 2838, 2849, 2852, 2854, 2858, 2862, 2864, 2865, 2866, 2867, 2871, 2875, 2881, 2889, 2891, 2892, 2893, 2894, 2896, 2900, 2901, 2902, 2906, 2911, 2912, 2915, 2916, 2917, 2931, 2934, 2936, 2937, 2940, 2948, 2950, 2955, 2961, 2963, 2964, 2966, 2967, 2970, 2972, 2973, 2978, 2980, 2987, 2990, 2992, 2993, 3008, 3009, 3011, 3015, 3019, 3022, 3023, 3024, 3026, 3029, 3030, 3034, 3040, 3045, 3047, 3049, 3051, 3056, 3057, 3058, 3061, 3062, 3063, 3065, 3068, 3069, 3075, 3076, 3078, 3083, 3084, 3085, 3087, 3093, 3094, 3098, 3100, 3101, 3104, 3108, 3111, 3113, 3116, 3123, 3125, 3128, 3129, 3131, 3137, 3138, 3139, 3143, 3153, 3155, 3156, 3158, 3160, 3161, 3164, 3166, 3167, 3170, 3171, 3173, 3175, 3181, 3182, 3183, 3186, 3189, 3198, 3201, 3204, 3205, 3208, 3210, 3211, 3214, 3217, 3221, 3225, 3227, 3228, 3229, 3240, 3243, 3246, 3247, 3251, 3252, 3256, 3258, 3259, 3261, 3262, 3263, 3264, 3267, 3269, 3270, 3271, 3275, 3277, 3279, 3281, 3288, 3290, 3291, 3294, 3297, 3302, 3304, 3307, 3309, 3311, 3312, 3317, 3318, 3320, 3321, 3329, 3331, 3332, 3336, 3337, 3338, 3342, 3343, 3344, 3345, 3346, 3355, 3363, 3367, 3369, 3375, 3376, 3378, 3381, 3385, 3386, 3388, 3389, 3391, 3394, 3397, 3399, 3401, 3403, 3404, 3406, 3408, 3411, 3412, 3413, 3414, 3421, 3427, 3428, 3429, 3430, 3431, 3432, 3435, 3438, 3445, 3447, 3450, 3451, 3452, 3455, 3456, 3458, 3459, 3464, 3465, 3471, 3472, 3473, 3476, 3478, 3479, 3480, 3481, 3485, 3488, 3494, 3498, 3499, 3502, 3503, 3504, 3506, 3508, 3511, 3512, 3520, 3521, 3522, 3523, 3524, 3526, 3528, 3529, 3535, 3539, 3540, 3541, 3544, 3547, 3549, 3554, 3557, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3573, 3574, 3577, 3579, 3581, 3587, 3591, 3592, 3593, 3604, 3606, 3607, 3608, 3611, 3612, 3615, 3617, 3622, 3626, 3640, 3641, 3651, 3654, 3658, 3661, 3662, 3663, 3665, 3670, 3672, 3677, 3678, 3680, 3681, 3691, 3692, 3694, 3695, 3697, 3698, 3702, 3704, 3705, 3706, 3707, 3708, 3709, 3711, 3712, 3717, 3719, 3728, 3731, 3741, 3746, 3750, 3753, 3754, 3756, 3759, 3764, 3765, 3767, 3770, 3771, 3774, 3775, 3777, 3782, 3789, 3790, 3792, 3793, 3794, 3795, 3796, 3797, 3799, 3800, 3802, 3804, 3805, 3806, 3808, 3811, 3813, 3814, 3815, 3816, 3819, 3821, 3827, 3835, 3836, 3837, 3844, 3845, 3850, 3852, 3853, 3854, 3855, 3859, 3864, 3865, 3866, 3867, 3868, 3870, 3871, 3872, 3873, 3883, 3884, 3890, 3897, 3898, 3901, 3902, 3903, 3908, 3917, 3919, 3920, 3921, 3925, 3926, 3928, 3929, 3930, 3931, 3932, 3933, 3936, 3939, 3941, 3944, 3945, 3946, 3951, 3957, 3963, 3967, 3976, 3977, 3979, 3982, 3983, 3989, 3990, 3992, 3995, 3996, 3997, 3998, 4001, 4002, 4003, 4007, 4008, 4010, 4012, 4015, 4016, 4018, 4019, 4021, 4026, 4027, 4031, 4032, 4033, 4034, 4035, 4036, 4038, 4041, 4043, 4044, 4045, 4050, 4052, 4058, 4059, 4063, 4064, 4065, 4069, 4070, 4071, 4072, 4073, 4075, 4076, 4078, 4083, 4084, 4085, 4086, 4088, 4089, 4090, 4093, 4095], 20: [0, 4, 6, 7, 8, 10, 11, 12, 15, 16, 19, 21, 23, 26, 28, 34, 35, 38, 40, 42, 44, 52, 54, 57, 60, 67, 68, 70, 76, 84, 90, 91, 92, 95, 100, 108, 111, 117, 120, 121, 126, 127, 128, 129, 131, 140, 141, 143, 145, 148, 153, 154, 155, 162, 168, 170, 178, 181, 184, 186, 187, 188, 192, 195, 198, 199, 200, 204, 211, 216, 221, 226, 232, 235, 237, 239, 244, 246, 247, 248, 250, 251, 255, 257, 259, 260, 262, 265, 266, 267, 272, 273, 274, 275, 281, 289, 291, 292, 293, 294, 295, 297, 298, 303, 304, 308, 309, 313, 315, 318, 321, 325, 330, 331, 333, 334, 335, 338, 339, 340, 342, 343, 344, 346, 351, 355, 357, 358, 362, 364, 366, 369, 372, 379, 385, 386, 388, 393, 398, 401, 403, 404, 406, 407, 409, 411, 413, 414, 417, 419, 422, 424, 425, 431, 435, 436, 437, 438, 439, 442, 443, 446, 450, 455, 464, 469, 470, 471, 472, 474, 475, 478, 480, 482, 491, 492, 493, 497, 500, 505, 508, 509, 512, 513, 516, 520, 531, 534, 538, 540, 541, 544, 545, 546, 547, 554, 556, 558, 560, 561, 562, 568, 570, 573, 575, 576, 577, 579, 583, 585, 586, 588, 598, 606, 609, 610, 611, 614, 615, 616, 625, 629, 630, 636, 638, 643, 644, 645, 646, 665, 667, 668, 669, 671, 674, 675, 676, 681, 685, 688, 690, 695, 701, 707, 708, 710, 717, 718, 719, 723, 726, 727, 728, 733, 734, 735, 738, 741, 743, 749, 751, 753, 754, 756, 759, 760, 764, 768, 769, 771, 773, 775, 779, 780, 781, 784, 785, 788, 789, 793, 795, 796, 799, 805, 806, 807, 810, 814, 816, 817, 824, 826, 827, 830, 831, 832, 833, 839, 840, 841, 843, 853, 860, 865, 866, 869, 870, 872, 873, 875, 879, 880, 883, 889, 892, 893, 899, 900, 904, 905, 908, 917, 921, 924, 929, 930, 933, 935, 936, 937, 939, 941, 943, 944, 946, 947, 949, 950, 951, 953, 954, 955, 956, 957, 962, 965, 968, 969, 977, 980, 990, 994, 995, 999, 1000, 1001, 1004, 1005, 1006, 1008, 1011, 1013, 1014, 1016, 1019, 1020, 1021, 1025, 1026, 1027, 1032, 1034, 1035, 1038, 1039, 1040, 1041, 1043, 1050, 1051, 1053, 1056, 1057, 1066, 1068, 1069, 1073, 1074, 1075, 1077, 1080, 1081, 1085, 1087, 1089, 1094, 1095, 1097, 1100, 1105, 1106, 1107, 1108, 1110, 1112, 1117, 1118, 1119, 1125, 1133, 1139, 1141, 1145, 1146, 1147, 1154, 1157, 1161, 1166, 1181, 1182, 1183, 1184, 1189, 1199, 1202, 1203, 1205, 1210, 1211, 1214, 1217, 1225, 1228, 1231, 1239, 1243, 1248, 1249, 1255, 1259, 1261, 1264, 1273, 1280, 1282, 1283, 1285, 1289, 1290, 1299, 1302, 1303, 1305, 1311, 1312, 1316, 1318, 1319, 1325, 1327, 1338, 1339, 1341, 1343, 1344, 1346, 1347, 1352, 1353, 1355, 1356, 1358, 1360, 1361, 1363, 1364, 1367, 1370, 1373, 1374, 1379, 1380, 1381, 1387, 1397, 1398, 1401, 1402, 1403, 1405, 1410, 1416, 1418, 1419, 1421, 1430, 1431, 1432, 1434, 1439, 1441, 1446, 1450, 1451, 1456, 1463, 1464, 1470, 1473, 1476, 1482, 1483, 1484, 1489, 1495, 1497, 1499, 1506, 1510, 1514, 1521, 1529, 1530, 1531, 1532, 1535, 1536, 1539, 1549, 1552, 1555, 1558, 1561, 1567, 1571, 1580, 1589, 1590, 1594, 1598, 1600, 1603, 1604, 1608, 1613, 1619, 1621, 1624, 1626, 1627, 1628, 1629, 1630, 1637, 1642, 1645, 1648, 1650, 1651, 1654, 1658, 1678, 1680, 1683, 1689, 1691, 1693, 1697, 1701, 1705, 1711, 1716, 1718, 1719, 1725, 1726, 1727, 1730, 1735, 1737, 1738, 1741, 1747, 1748, 1754, 1756, 1757, 1758, 1759, 1761, 1768, 1770, 1772, 1773, 1774, 1775, 1779, 1782, 1785, 1786, 1787, 1788, 1790, 1792, 1793, 1795, 1800, 1808, 1809, 1814, 1816, 1818, 1820, 1823, 1826, 1828, 1830, 1834, 1839, 1840, 1841, 1845, 1856, 1862, 1863, 1864, 1869, 1871, 1875, 1881, 1883, 1886, 1887, 1894, 1901, 1902, 1903, 1904, 1905, 1906, 1908, 1910, 1920, 1926, 1927, 1930, 1941, 1943, 1950, 1957, 1958, 1960, 1961, 1963, 1965, 1966, 1968, 1971, 1973, 1976, 1978, 1979, 1983, 1985, 1986, 1988, 1992, 1996, 2002, 2005, 2006, 2014, 2017, 2019, 2021, 2022, 2026, 2033, 2034, 2035, 2039, 2040, 2047, 2048, 2054, 2056, 2058, 2059, 2060, 2063, 2067, 2068, 2069, 2072, 2074, 2078, 2079, 2081, 2082, 2086, 2090, 2091, 2096, 2100, 2102, 2103, 2104, 2106, 2108, 2110, 2113, 2117, 2122, 2123, 2129, 2130, 2132, 2138, 2140, 2144, 2145, 2147, 2149, 2150, 2153, 2155, 2160, 2163, 2167, 2173, 2176, 2180, 2183, 2191, 2194, 2200, 2203, 2204, 2205, 2207, 2209, 2212, 2213, 2217, 2219, 2220, 2223, 2226, 2227, 2228, 2229, 2230, 2231, 2237, 2241, 2247, 2251, 2255, 2267, 2275, 2277, 2278, 2279, 2281, 2283, 2284, 2293, 2295, 2299, 2300, 2302, 2303, 2305, 2307, 2312, 2319, 2320, 2322, 2323, 2324, 2326, 2329, 2335, 2336, 2339, 2341, 2342, 2344, 2346, 2349, 2355, 2356, 2357, 2362, 2364, 2368, 2370, 2372, 2377, 2378, 2380, 2382, 2383, 2385, 2393, 2401, 2403, 2406, 2408, 2417, 2421, 2424, 2426, 2429, 2435, 2440, 2442, 2444, 2445, 2446, 2451, 2458, 2461, 2466, 2471, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2491, 2492, 2493, 2495, 2496, 2498, 2499, 2501, 2505, 2508, 2514, 2516, 2518, 2519, 2520, 2521, 2522, 2525, 2527, 2529, 2537, 2544, 2545, 2546, 2548, 2551, 2552, 2553, 2556, 2561, 2567, 2568, 2570, 2571, 2573, 2574, 2579, 2581, 2582, 2587, 2591, 2596, 2597, 2602, 2607, 2608, 2610, 2612, 2613, 2614, 2616, 2619, 2623, 2624, 2625, 2628, 2629, 2633, 2634, 2636, 2638, 2654, 2656, 2660, 2664, 2669, 2672, 2675, 2678, 2680, 2682, 2686, 2691, 2695, 2696, 2701, 2703, 2705, 2706, 2708, 2710, 2716, 2719, 2724, 2725, 2726, 2730, 2732, 2737, 2738, 2740, 2742, 2748, 2750, 2758, 2761, 2765, 2767, 2769, 2771, 2772, 2773, 2779, 2780, 2781, 2789, 2791, 2793, 2798, 2809, 2813, 2814, 2815, 2819, 2822, 2823, 2832, 2836, 2837, 2838, 2839, 2840, 2841, 2843, 2851, 2853, 2855, 2856, 2858, 2859, 2860, 2861, 2864, 2866, 2867, 2872, 2877, 2880, 2881, 2883, 2886, 2887, 2888, 2891, 2892, 2893, 2894, 2901, 2909, 2910, 2911, 2915, 2916, 2917, 2919, 2921, 2922, 2926, 2929, 2931, 2932, 2933, 2936, 2940, 2944, 2945, 2950, 2951, 2953, 2955, 2957, 2959, 2961, 2963, 2964, 2965, 2966, 2968, 2980, 2984, 2986, 2987, 2988, 2990, 2992, 3001, 3003, 3004, 3007, 3012, 3014, 3021, 3022, 3041, 3045, 3051, 3052, 3055, 3056, 3058, 3059, 3061, 3062, 3064, 3066, 3071, 3077, 3078, 3087, 3088, 3092, 3093, 3094, 3095, 3096, 3099, 3100, 3101, 3112, 3118, 3119, 3122, 3123, 3127, 3129, 3130, 3131, 3132, 3143, 3144, 3145, 3149, 3150, 3151, 3152, 3155, 3156, 3158, 3161, 3164, 3165, 3166, 3170, 3171, 3172, 3173, 3178, 3179, 3180, 3183, 3185, 3189, 3190, 3197, 3200, 3203, 3205, 3206, 3208, 3213, 3219, 3223, 3224, 3225, 3227, 3230, 3231, 3232, 3234, 3236, 3237, 3240, 3243, 3246, 3249, 3251, 3253, 3255, 3258, 3261, 3265, 3266, 3272, 3278, 3279, 3280, 3282, 3287, 3290, 3295, 3299, 3300, 3302, 3303, 3304, 3307, 3308, 3317, 3318, 3321, 3322, 3324, 3328, 3329, 3335, 3338, 3340, 3343, 3347, 3348, 3349, 3350, 3352, 3356, 3361, 3363, 3365, 3368, 3371, 3377, 3378, 3385, 3386, 3387, 3388, 3389, 3390, 3395, 3396, 3398, 3400, 3406, 3409, 3415, 3421, 3422, 3423, 3425, 3427, 3431, 3432, 3441, 3451, 3453, 3454, 3455, 3459, 3466, 3469, 3474, 3478, 3482, 3486, 3488, 3495, 3511, 3513, 3524, 3525, 3526, 3534, 3535, 3536, 3538, 3539, 3545, 3550, 3556, 3558, 3561, 3573, 3576, 3577, 3578, 3579, 3581, 3583, 3591, 3593, 3597, 3599, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3612, 3616, 3620, 3622, 3624, 3629, 3630, 3631, 3635, 3639, 3642, 3643, 3647, 3649, 3650, 3652, 3655, 3658, 3659, 3660, 3665, 3667, 3669, 3672, 3674, 3675, 3680, 3684, 3691, 3696, 3697, 3699, 3700, 3701, 3709, 3710, 3712, 3720, 3727, 3728, 3729, 3737, 3741, 3744, 3749, 3752, 3755, 3756, 3758, 3765, 3767, 3772, 3773, 3777, 3779, 3780, 3782, 3789, 3790, 3792, 3793, 3796, 3801, 3802, 3804, 3811, 3813, 3819, 3829, 3830, 3831, 3832, 3836, 3837, 3845, 3847, 3853, 3856, 3862, 3863, 3865, 3867, 3871, 3875, 3878, 3879, 3880, 3881, 3883, 3884, 3885, 3886, 3889, 3890, 3894, 3895, 3896, 3897, 3899, 3909, 3916, 3917, 3924, 3926, 3927, 3935, 3936, 3939, 3940, 3942, 3944, 3947, 3950, 3953, 3959, 3961, 3963, 3965, 3966, 3968, 3969, 3970, 3975, 3976, 3977, 3981, 3988, 3989, 3993, 3996, 3997, 3998, 4001, 4003, 4008, 4009, 4020, 4022, 4024, 4026, 4031, 4034, 4035, 4037, 4040, 4042, 4043, 4045, 4049, 4051, 4053, 4057, 4060, 4061, 4063, 4064, 4071, 4072, 4074, 4075, 4077, 4081, 4084, 4092], 21: [2, 5, 9, 15, 18, 19, 20, 21, 25, 37, 38, 43, 50, 54, 62, 63, 66, 67, 79, 84, 102, 104, 112, 129, 140, 145, 153, 160, 161, 166, 172, 173, 181, 188, 191, 197, 201, 203, 209, 213, 215, 216, 217, 218, 220, 236, 247, 253, 255, 257, 258, 262, 263, 264, 267, 270, 275, 281, 282, 288, 292, 295, 296, 298, 301, 306, 320, 331, 346, 348, 358, 363, 367, 373, 376, 378, 383, 386, 394, 404, 407, 410, 412, 420, 421, 424, 427, 435, 436, 450, 458, 459, 460, 465, 469, 473, 486, 490, 492, 493, 499, 501, 506, 508, 515, 518, 521, 525, 539, 541, 544, 546, 553, 558, 565, 567, 577, 586, 591, 592, 612, 628, 631, 633, 635, 640, 642, 644, 646, 647, 672, 674, 675, 682, 688, 697, 704, 707, 716, 723, 728, 729, 736, 739, 745, 746, 748, 750, 752, 753, 754, 755, 760, 761, 767, 774, 779, 782, 786, 788, 797, 800, 804, 805, 806, 807, 809, 810, 814, 817, 818, 823, 830, 833, 836, 848, 851, 856, 857, 858, 859, 862, 865, 867, 873, 880, 881, 883, 885, 886, 889, 892, 895, 897, 898, 909, 910, 930, 932, 935, 939, 952, 953, 957, 976, 978, 982, 985, 986, 993, 1000, 1010, 1019, 1026, 1040, 1042, 1043, 1045, 1046, 1049, 1054, 1056, 1057, 1059, 1061, 1062, 1065, 1066, 1073, 1086, 1089, 1096, 1100, 1102, 1108, 1111, 1116, 1126, 1129, 1141, 1142, 1154, 1155, 1156, 1158, 1164, 1173, 1178, 1181, 1185, 1191, 1207, 1213, 1214, 1217, 1222, 1230, 1233, 1249, 1253, 1254, 1261, 1266, 1267, 1269, 1273, 1275, 1276, 1277, 1298, 1305, 1309, 1310, 1319, 1325, 1330, 1335, 1337, 1347, 1348, 1351, 1352, 1355, 1363, 1366, 1374, 1378, 1387, 1388, 1389, 1391, 1398, 1406, 1409, 1411, 1414, 1415, 1425, 1427, 1428, 1432, 1437, 1447, 1451, 1457, 1465, 1467, 1471, 1474, 1481, 1487, 1488, 1494, 1499, 1507, 1511, 1514, 1518, 1524, 1533, 1540, 1541, 1548, 1550, 1561, 1576, 1577, 1581, 1585, 1590, 1591, 1593, 1603, 1611, 1618, 1623, 1627, 1632, 1636, 1637, 1638, 1644, 1645, 1646, 1647, 1650, 1652, 1653, 1661, 1666, 1669, 1679, 1680, 1681, 1682, 1687, 1690, 1691, 1696, 1697, 1703, 1716, 1717, 1724, 1727, 1736, 1737, 1746, 1749, 1764, 1773, 1779, 1783, 1795, 1797, 1801, 1808, 1812, 1823, 1827, 1847, 1851, 1853, 1859, 1861, 1866, 1880, 1883, 1889, 1897, 1901, 1907, 1919, 1929, 1930, 1935, 1936, 1937, 1947, 1949, 1950, 1954, 1957, 1958, 1959, 1962, 1965, 1980, 1983, 1990, 1996, 1997, 1998, 2002, 2016, 2027, 2036, 2037, 2040, 2047, 2048, 2049, 2053, 2056, 2063, 2075, 2081, 2084, 2086, 2095, 2098, 2099, 2109, 2110, 2116, 2120, 2134, 2139, 2142, 2148, 2150, 2154, 2156, 2167, 2174, 2182, 2185, 2187, 2191, 2192, 2208, 2219, 2227, 2235, 2241, 2245, 2247, 2248, 2249, 2251, 2253, 2257, 2260, 2261, 2263, 2266, 2268, 2269, 2276, 2280, 2288, 2290, 2297, 2305, 2306, 2308, 2309, 2318, 2322, 2325, 2331, 2332, 2341, 2342, 2355, 2356, 2357, 2360, 2369, 2370, 2371, 2375, 2378, 2386, 2388, 2390, 2391, 2395, 2396, 2397, 2399, 2400, 2407, 2410, 2411, 2413, 2430, 2433, 2436, 2437, 2442, 2450, 2457, 2461, 2462, 2474, 2475, 2483, 2487, 2492, 2499, 2506, 2507, 2508, 2514, 2518, 2530, 2536, 2546, 2554, 2556, 2557, 2562, 2572, 2573, 2574, 2590, 2592, 2594, 2595, 2596, 2598, 2604, 2611, 2613, 2614, 2631, 2632, 2633, 2640, 2644, 2646, 2651, 2652, 2654, 2655, 2656, 2657, 2664, 2678, 2684, 2685, 2689, 2693, 2697, 2704, 2711, 2719, 2721, 2726, 2737, 2759, 2761, 2768, 2769, 2773, 2776, 2781, 2784, 2789, 2793, 2796, 2799, 2803, 2808, 2810, 2812, 2813, 2815, 2818, 2822, 2823, 2827, 2829, 2843, 2844, 2851, 2861, 2863, 2867, 2879, 2885, 2888, 2889, 2893, 2897, 2898, 2903, 2915, 2918, 2921, 2940, 2947, 2948, 2949, 2955, 2969, 2976, 2977, 2987, 2993, 2995, 3009, 3014, 3022, 3026, 3029, 3033, 3035, 3037, 3038, 3039, 3043, 3044, 3046, 3050, 3053, 3054, 3066, 3071, 3075, 3076, 3084, 3087, 3092, 3099, 3115, 3116, 3125, 3131, 3132, 3134, 3136, 3138, 3147, 3153, 3155, 3157, 3163, 3165, 3169, 3170, 3177, 3189, 3201, 3214, 3220, 3227, 3228, 3230, 3233, 3236, 3240, 3243, 3246, 3248, 3251, 3252, 3256, 3263, 3264, 3269, 3271, 3273, 3287, 3296, 3320, 3321, 3332, 3333, 3335, 3338, 3340, 3345, 3347, 3356, 3358, 3360, 3361, 3362, 3365, 3369, 3373, 3375, 3379, 3386, 3395, 3401, 3405, 3414, 3415, 3422, 3425, 3426, 3436, 3437, 3441, 3450, 3462, 3463, 3471, 3472, 3477, 3479, 3481, 3485, 3491, 3501, 3507, 3508, 3525, 3528, 3531, 3535, 3536, 3550, 3554, 3557, 3563, 3567, 3572, 3574, 3580, 3582, 3590, 3592, 3594, 3596, 3600, 3608, 3609, 3611, 3617, 3627, 3633, 3638, 3640, 3641, 3660, 3667, 3677, 3692, 3703, 3705, 3709, 3711, 3712, 3719, 3723, 3726, 3730, 3731, 3736, 3742, 3753, 3754, 3756, 3757, 3759, 3761, 3790, 3797, 3798, 3806, 3808, 3819, 3820, 3823, 3828, 3830, 3834, 3837, 3841, 3842, 3860, 3863, 3865, 3870, 3873, 3878, 3880, 3886, 3889, 3890, 3896, 3898, 3909, 3911, 3922, 3931, 3937, 3941, 3942, 3965, 3968, 3970, 3971, 3974, 3979, 3984, 3991, 3992, 3993, 4000, 4003, 4012, 4013, 4016, 4024, 4027, 4029, 4030, 4033, 4035, 4037, 4067, 4078, 4080, 4095], 22: [4, 6, 9, 12, 16, 17, 18, 19, 22, 23, 25, 27, 28, 32, 34, 35, 41, 42, 43, 44, 45, 48, 53, 55, 58, 63, 64, 65, 67, 69, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 98, 99, 100, 102, 104, 106, 108, 110, 111, 114, 118, 120, 125, 130, 133, 135, 137, 139, 140, 142, 144, 145, 148, 149, 150, 152, 158, 163, 164, 166, 175, 179, 184, 186, 187, 188, 195, 202, 204, 205, 208, 209, 210, 212, 216, 217, 220, 222, 223, 225, 230, 234, 237, 239, 243, 244, 245, 248, 252, 257, 258, 260, 263, 265, 266, 273, 278, 279, 282, 286, 287, 290, 291, 293, 296, 298, 301, 303, 304, 306, 308, 311, 312, 313, 314, 315, 317, 320, 328, 329, 331, 332, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344, 346, 350, 353, 356, 357, 358, 360, 361, 362, 363, 364, 365, 367, 369, 370, 375, 377, 378, 379, 380, 381, 382, 383, 384, 387, 388, 391, 393, 395, 396, 397, 400, 401, 404, 406, 408, 411, 414, 415, 417, 418, 421, 424, 429, 430, 431, 432, 434, 435, 436, 442, 450, 452, 453, 454, 458, 460, 463, 465, 466, 469, 474, 475, 476, 478, 479, 481, 485, 487, 490, 492, 493, 497, 498, 499, 502, 511, 513, 517, 518, 519, 521, 526, 530, 533, 534, 535, 536, 538, 540, 541, 544, 548, 556, 557, 562, 563, 566, 569, 571, 572, 573, 575, 578, 585, 586, 589, 592, 593, 597, 598, 599, 603, 604, 607, 610, 613, 614, 615, 620, 621, 623, 627, 629, 631, 632, 635, 639, 640, 643, 644, 646, 648, 652, 653, 656, 660, 661, 666, 667, 670, 671, 675, 678, 679, 680, 684, 685, 689, 695, 699, 700, 702, 706, 709, 713, 714, 716, 717, 719, 721, 722, 724, 726, 727, 728, 729, 730, 731, 732, 738, 739, 740, 741, 744, 746, 753, 757, 758, 759, 760, 761, 762, 773, 775, 776, 778, 780, 782, 783, 790, 791, 792, 793, 797, 798, 802, 806, 808, 812, 816, 824, 827, 829, 830, 833, 834, 835, 836, 837, 838, 840, 841, 843, 846, 849, 852, 855, 867, 869, 875, 876, 877, 879, 885, 886, 892, 897, 900, 902, 903, 905, 911, 914, 915, 916, 920, 925, 928, 929, 930, 931, 934, 936, 938, 940, 944, 947, 949, 950, 954, 956, 959, 962, 963, 964, 967, 969, 971, 973, 974, 975, 976, 977, 978, 981, 984, 988, 990, 992, 993, 995, 998, 999, 1001, 1008, 1010, 1011, 1012, 1015, 1016, 1017, 1021, 1023, 1030, 1031, 1032, 1035, 1038, 1044, 1045, 1057, 1059, 1060, 1063, 1072, 1073, 1074, 1078, 1079, 1080, 1081, 1082, 1084, 1086, 1088, 1089, 1092, 1093, 1094, 1100, 1101, 1103, 1104, 1106, 1107, 1111, 1114, 1115, 1119, 1132, 1133, 1136, 1138, 1142, 1147, 1150, 1151, 1152, 1155, 1157, 1158, 1161, 1162, 1165, 1166, 1170, 1176, 1177, 1180, 1181, 1182, 1183, 1189, 1191, 1192, 1193, 1194, 1196, 1198, 1199, 1201, 1202, 1205, 1207, 1210, 1217, 1219, 1220, 1223, 1224, 1229, 1232, 1234, 1237, 1241, 1245, 1249, 1250, 1252, 1255, 1256, 1257, 1258, 1260, 1261, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1273, 1275, 1276, 1278, 1279, 1282, 1284, 1287, 1288, 1294, 1296, 1299, 1302, 1303, 1304, 1305, 1307, 1308, 1309, 1310, 1311, 1312, 1317, 1319, 1323, 1326, 1328, 1329, 1333, 1334, 1336, 1337, 1341, 1342, 1343, 1344, 1346, 1348, 1349, 1350, 1352, 1353, 1355, 1358, 1361, 1366, 1367, 1372, 1374, 1375, 1377, 1383, 1384, 1387, 1389, 1395, 1400, 1402, 1405, 1406, 1407, 1408, 1409, 1410, 1412, 1414, 1415, 1418, 1419, 1422, 1425, 1426, 1427, 1430, 1436, 1440, 1447, 1449, 1450, 1454, 1455, 1459, 1461, 1464, 1465, 1468, 1472, 1473, 1484, 1485, 1487, 1490, 1491, 1492, 1493, 1499, 1500, 1501, 1504, 1506, 1507, 1509, 1511, 1512, 1513, 1516, 1517, 1518, 1521, 1522, 1523, 1524, 1525, 1528, 1531, 1533, 1536, 1540, 1543, 1544, 1545, 1546, 1550, 1552, 1554, 1557, 1558, 1561, 1566, 1568, 1570, 1571, 1572, 1574, 1575, 1577, 1579, 1580, 1584, 1585, 1588, 1591, 1592, 1593, 1594, 1596, 1598, 1600, 1602, 1604, 1606, 1610, 1612, 1613, 1615, 1616, 1617, 1619, 1622, 1625, 1627, 1638, 1640, 1641, 1646, 1649, 1650, 1655, 1656, 1660, 1663, 1665, 1667, 1668, 1674, 1675, 1681, 1682, 1683, 1686, 1687, 1692, 1694, 1695, 1699, 1701, 1704, 1710, 1715, 1722, 1724, 1725, 1727, 1731, 1732, 1734, 1735, 1736, 1737, 1738, 1740, 1743, 1744, 1745, 1749, 1753, 1755, 1758, 1759, 1760, 1764, 1765, 1767, 1770, 1771, 1772, 1776, 1779, 1781, 1782, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1793, 1795, 1797, 1799, 1800, 1803, 1806, 1807, 1811, 1812, 1813, 1814, 1816, 1819, 1823, 1826, 1834, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1847, 1849, 1850, 1852, 1856, 1858, 1861, 1862, 1863, 1864, 1868, 1870, 1871, 1879, 1881, 1885, 1888, 1889, 1890, 1892, 1893, 1894, 1900, 1904, 1906, 1909, 1912, 1915, 1921, 1923, 1933, 1934, 1936, 1939, 1941, 1942, 1943, 1947, 1951, 1953, 1954, 1957, 1960, 1963, 1964, 1965, 1967, 1969, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1983, 1984, 1985, 1986, 1989, 1991, 1993, 1994, 1996, 1998, 2004, 2008, 2009, 2010, 2011, 2012, 2014, 2018, 2020, 2021, 2028, 2030, 2033, 2035, 2037, 2039, 2042, 2046, 2047, 2049, 2050, 2055, 2056, 2057, 2058, 2060, 2061, 2062, 2063, 2066, 2067, 2069, 2070, 2071, 2072, 2074, 2078, 2079, 2084, 2085, 2086, 2088, 2089, 2090, 2093, 2094, 2095, 2098, 2101, 2102, 2106, 2110, 2118, 2119, 2120, 2123, 2128, 2129, 2132, 2133, 2135, 2137, 2139, 2141, 2142, 2144, 2146, 2147, 2153, 2156, 2159, 2161, 2163, 2164, 2167, 2173, 2174, 2175, 2176, 2177, 2179, 2181, 2182, 2186, 2188, 2192, 2193, 2195, 2196, 2198, 2199, 2200, 2202, 2205, 2210, 2213, 2214, 2216, 2219, 2220, 2222, 2223, 2229, 2230, 2231, 2234, 2236, 2238, 2242, 2243, 2246, 2248, 2249, 2253, 2255, 2256, 2257, 2258, 2260, 2262, 2264, 2266, 2272, 2277, 2278, 2280, 2281, 2283, 2286, 2287, 2288, 2289, 2290, 2292, 2301, 2306, 2310, 2311, 2318, 2319, 2320, 2326, 2328, 2329, 2332, 2335, 2338, 2339, 2340, 2343, 2348, 2349, 2350, 2352, 2356, 2357, 2360, 2365, 2366, 2368, 2371, 2373, 2377, 2378, 2380, 2381, 2387, 2389, 2390, 2393, 2397, 2399, 2400, 2403, 2407, 2415, 2420, 2422, 2425, 2427, 2433, 2434, 2435, 2436, 2439, 2441, 2442, 2445, 2447, 2449, 2454, 2457, 2459, 2466, 2468, 2470, 2473, 2474, 2475, 2479, 2483, 2484, 2485, 2492, 2493, 2496, 2498, 2503, 2504, 2508, 2509, 2511, 2512, 2514, 2516, 2517, 2518, 2520, 2521, 2523, 2526, 2527, 2529, 2531, 2534, 2535, 2536, 2537, 2539, 2540, 2543, 2546, 2549, 2550, 2556, 2557, 2561, 2562, 2563, 2565, 2570, 2572, 2574, 2575, 2576, 2578, 2581, 2584, 2588, 2589, 2592, 2593, 2596, 2598, 2599, 2602, 2603, 2604, 2605, 2607, 2610, 2612, 2613, 2614, 2616, 2619, 2620, 2621, 2622, 2623, 2626, 2628, 2632, 2634, 2636, 2637, 2639, 2640, 2642, 2643, 2644, 2645, 2648, 2649, 2651, 2655, 2656, 2660, 2661, 2662, 2667, 2671, 2673, 2676, 2677, 2678, 2679, 2682, 2686, 2688, 2689, 2691, 2693, 2694, 2698, 2699, 2701, 2705, 2708, 2709, 2716, 2719, 2720, 2721, 2722, 2723, 2724, 2726, 2727, 2728, 2730, 2731, 2735, 2736, 2738, 2739, 2744, 2745, 2746, 2747, 2751, 2752, 2755, 2763, 2765, 2767, 2768, 2769, 2771, 2773, 2775, 2776, 2780, 2782, 2783, 2785, 2790, 2793, 2794, 2797, 2798, 2802, 2806, 2808, 2809, 2811, 2812, 2816, 2817, 2819, 2820, 2821, 2822, 2823, 2826, 2827, 2828, 2829, 2832, 2833, 2834, 2835, 2837, 2838, 2839, 2842, 2843, 2848, 2853, 2854, 2855, 2857, 2858, 2860, 2862, 2866, 2867, 2868, 2871, 2872, 2874, 2876, 2877, 2878, 2879, 2880, 2883, 2884, 2886, 2887, 2889, 2891, 2892, 2893, 2897, 2898, 2899, 2901, 2902, 2904, 2907, 2914, 2916, 2919, 2922, 2923, 2937, 2938, 2939, 2944, 2947, 2948, 2949, 2950, 2952, 2954, 2955, 2958, 2961, 2967, 2969, 2970, 2973, 2977, 2978, 2980, 2984, 2989, 2992, 2994, 2998, 3000, 3001, 3006, 3007, 3009, 3010, 3011, 3012, 3014, 3015, 3017, 3022, 3029, 3030, 3031, 3033, 3035, 3039, 3042, 3044, 3046, 3048, 3050, 3055, 3059, 3061, 3062, 3067, 3068, 3074, 3075, 3078, 3082, 3084, 3089, 3090, 3092, 3093, 3105, 3108, 3111, 3112, 3113, 3115, 3117, 3119, 3120, 3121, 3124, 3126, 3131, 3133, 3134, 3135, 3136, 3137, 3139, 3140, 3145, 3147, 3150, 3153, 3155, 3158, 3161, 3164, 3167, 3171, 3172, 3173, 3176, 3181, 3182, 3183, 3185, 3188, 3189, 3192, 3196, 3197, 3199, 3204, 3209, 3211, 3212, 3213, 3214, 3215, 3218, 3219, 3221, 3225, 3226, 3230, 3233, 3237, 3242, 3246, 3249, 3252, 3253, 3258, 3262, 3264, 3265, 3266, 3267, 3269, 3270, 3273, 3274, 3275, 3278, 3279, 3280, 3281, 3282, 3285, 3287, 3288, 3289, 3291, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3303, 3305, 3306, 3309, 3311, 3313, 3314, 3315, 3317, 3318, 3322, 3323, 3325, 3326, 3330, 3331, 3333, 3337, 3338, 3340, 3341, 3343, 3345, 3346, 3347, 3349, 3350, 3351, 3352, 3353, 3355, 3356, 3358, 3362, 3364, 3365, 3367, 3368, 3371, 3372, 3375, 3376, 3378, 3381, 3382, 3383, 3384, 3385, 3386, 3388, 3389, 3392, 3394, 3396, 3397, 3398, 3399, 3400, 3402, 3404, 3406, 3409, 3413, 3427, 3430, 3432, 3433, 3434, 3435, 3436, 3439, 3440, 3442, 3443, 3444, 3446, 3447, 3449, 3451, 3453, 3454, 3458, 3462, 3464, 3465, 3466, 3468, 3471, 3473, 3477, 3483, 3484, 3486, 3487, 3488, 3489, 3490, 3494, 3495, 3496, 3500, 3502, 3505, 3509, 3510, 3513, 3517, 3519, 3526, 3530, 3533, 3537, 3540, 3541, 3543, 3544, 3546, 3548, 3549, 3550, 3552, 3553, 3556, 3559, 3563, 3564, 3565, 3566, 3570, 3571, 3575, 3576, 3578, 3580, 3583, 3584, 3587, 3588, 3590, 3592, 3594, 3597, 3598, 3601, 3603, 3604, 3606, 3613, 3615, 3616, 3617, 3619, 3621, 3622, 3624, 3627, 3633, 3635, 3639, 3642, 3643, 3648, 3649, 3650, 3654, 3655, 3656, 3661, 3664, 3666, 3668, 3670, 3672, 3680, 3685, 3686, 3687, 3688, 3689, 3695, 3696, 3697, 3701, 3702, 3703, 3704, 3707, 3708, 3710, 3715, 3716, 3719, 3720, 3721, 3723, 3727, 3728, 3731, 3733, 3736, 3738, 3739, 3740, 3743, 3744, 3746, 3749, 3750, 3752, 3755, 3756, 3758, 3760, 3763, 3764, 3766, 3769, 3770, 3777, 3780, 3782, 3783, 3785, 3786, 3787, 3791, 3794, 3795, 3796, 3801, 3806, 3813, 3816, 3820, 3822, 3825, 3827, 3828, 3830, 3832, 3834, 3838, 3841, 3845, 3846, 3847, 3849, 3851, 3857, 3858, 3859, 3861, 3862, 3863, 3864, 3866, 3867, 3868, 3873, 3874, 3877, 3878, 3880, 3882, 3883, 3886, 3888, 3891, 3894, 3895, 3897, 3900, 3902, 3903, 3906, 3907, 3910, 3911, 3913, 3914, 3919, 3920, 3924, 3925, 3929, 3931, 3933, 3937, 3938, 3939, 3941, 3943, 3947, 3948, 3952, 3953, 3961, 3968, 3969, 3970, 3975, 3981, 3984, 3988, 3990, 3991, 3993, 3994, 3996, 4005, 4007, 4008, 4009, 4011, 4018, 4020, 4022, 4025, 4027, 4030, 4034, 4037, 4038, 4039, 4040, 4041, 4043, 4045, 4049, 4050, 4051, 4056, 4058, 4068, 4073, 4075, 4079, 4084, 4086, 4090, 4092, 4094], 23: [0, 27, 52, 54, 62, 88, 93, 102, 106, 109, 111, 114, 125, 147, 153, 167, 169, 179, 228, 231, 233, 235, 253, 254, 265, 279, 290, 295, 298, 310, 313, 339, 341, 362, 384, 409, 411, 417, 442, 462, 477, 500, 504, 519, 520, 522, 525, 535, 561, 599, 620, 623, 624, 644, 646, 653, 656, 662, 671, 672, 675, 684, 690, 716, 718, 719, 724, 725, 726, 754, 792, 798, 799, 807, 813, 817, 843, 856, 862, 872, 880, 897, 900, 905, 912, 913, 915, 918, 924, 927, 929, 947, 959, 974, 986, 991, 992, 1017, 1025, 1029, 1030, 1046, 1059, 1082, 1100, 1104, 1120, 1141, 1152, 1170, 1194, 1196, 1219, 1225, 1228, 1257, 1262, 1267, 1271, 1276, 1286, 1298, 1299, 1304, 1307, 1308, 1323, 1332, 1361, 1362, 1394, 1395, 1400, 1401, 1411, 1412, 1416, 1421, 1430, 1460, 1461, 1462, 1468, 1469, 1474, 1475, 1476, 1480, 1490, 1493, 1507, 1508, 1512, 1513, 1516, 1530, 1545, 1565, 1573, 1588, 1622, 1630, 1638, 1643, 1645, 1680, 1689, 1698, 1720, 1734, 1739, 1756, 1757, 1759, 1760, 1762, 1784, 1792, 1802, 1823, 1836, 1862, 1870, 1885, 1919, 1921, 1923, 1924, 1928, 1946, 1954, 1962, 1982, 1988, 1991, 2013, 2022, 2034, 2035, 2043, 2053, 2067, 2069, 2074, 2075, 2094, 2098, 2101, 2109, 2133, 2136, 2187, 2207, 2214, 2222, 2225, 2228, 2238, 2249, 2255, 2256, 2266, 2270, 2275, 2276, 2286, 2292, 2298, 2302, 2304, 2308, 2311, 2319, 2322, 2324, 2332, 2337, 2351, 2366, 2371, 2374, 2378, 2387, 2388, 2392, 2402, 2420, 2428, 2434, 2452, 2461, 2479, 2483, 2485, 2528, 2535, 2537, 2540, 2549, 2551, 2554, 2560, 2565, 2567, 2573, 2612, 2640, 2647, 2648, 2672, 2673, 2691, 2700, 2701, 2703, 2705, 2712, 2714, 2728, 2735, 2750, 2752, 2765, 2797, 2803, 2812, 2813, 2818, 2825, 2830, 2843, 2846, 2881, 2893, 2897, 2905, 2931, 2955, 2958, 2962, 2985, 3001, 3007, 3012, 3023, 3039, 3054, 3056, 3074, 3077, 3083, 3100, 3106, 3123, 3135, 3151, 3163, 3164, 3172, 3173, 3175, 3183, 3188, 3214, 3216, 3217, 3224, 3228, 3235, 3236, 3253, 3257, 3268, 3274, 3305, 3319, 3336, 3341, 3346, 3357, 3369, 3370, 3425, 3442, 3462, 3465, 3474, 3483, 3487, 3506, 3523, 3539, 3559, 3566, 3567, 3586, 3588, 3599, 3602, 3624, 3636, 3654, 3661, 3683, 3684, 3708, 3714, 3732, 3733, 3734, 3738, 3744, 3763, 3775, 3781, 3787, 3804, 3840, 3852, 3858, 3865, 3872, 3879, 3885, 3910, 3918, 3939, 3959, 3960, 3974, 3977, 3993, 4002, 4012, 4024, 4037, 4053, 4060, 4063, 4064, 4067, 4087], 24: [38, 65, 152, 180, 288, 400, 449, 450, 634, 726, 767, 785, 893, 949, 1192, 1299, 1352, 1369, 1425, 1428, 1468, 1713, 1775, 1837, 1859, 2186, 2377, 2692, 2991, 3264, 3315, 3318, 3338, 3438, 3566, 3727, 3746, 3788, 3991, 4043]}\n"
          ]
        }
      ],
      "source": [
        "# According to the threshold chosen, get the MLP dimensions per layer to be intervened on, i.e., the MLP neurons that belong to the digit circuit at that threshold\n",
        "\n",
        "# Open the right fisher score file\n",
        "with open(f\"Fisher_Scores/{model_name}/{task}/fisher_scores_{label}.json\", \"r\") as file:\n",
        "    fisher_scores_data = json.load(file) # return a victor of Fisher scores for each latent in layer_i. example: for llama3-8b (layer_16: sahpe(4096), layer_17:...)\n",
        "\n",
        "\n",
        "# Output dictionary\n",
        "layer_subspaces_map = {}\n",
        "\n",
        "# Iterate through best selected layers\n",
        "layers = layer_set # you can choose a subset of layers to test output [16,17]\n",
        "min_thresh = threshold # you can choose different threshold 0.8\n",
        "for layer in layers:\n",
        "    key = f\"layer_{layer}\"\n",
        "    if key in fisher_scores_data:\n",
        "        values = fisher_scores_data[key]\n",
        "        indices_above_threshold = [i for i, val in enumerate(values) if val > min_thresh] ### keep neurons indices that pass the a threshold\n",
        "        layer_subspaces_map[layer] = indices_above_threshold\n",
        "\n",
        "# Result\n",
        "print(layer_subspaces_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH3u8vtmRUWv",
        "outputId": "6a160071-0d53-49f9-af27-32d2c5d1acdb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "200it [02:37,  1.27it/s]\n"
          ]
        }
      ],
      "source": [
        "################################################\n",
        "# Perform Digit-Circuit Interventions on each data point #\n",
        "################################################\n",
        "\n",
        "# Iterate through each query in the dataset\n",
        "for j, entry in tqdm(enumerate(data)):\n",
        "    data_entry = []\n",
        "    model_layers = model.config.num_hidden_layers\n",
        "    window_size = 1\n",
        "\n",
        "    sentence = entry[\"one_shot_base\"]\n",
        "    sentence_intervention = entry[\"one_shot_source\"]\n",
        "\n",
        "    base = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Number of tokens\n",
        "    tokenized_input = tokenizer(sentence, return_tensors=\"pt\", return_offsets_mapping=True)\n",
        "    input_ids = tokenized_input[\"input_ids\"].to(device)\n",
        "    num_tokens = input_ids.shape[1]\n",
        "\n",
        "    ############################\n",
        "    # Clean Run for comparison #\n",
        "    ############################\n",
        "\n",
        "    inputs = [tokenizer(sentence, return_tensors=\"pt\").to(device),]\n",
        "    res = model(**inputs[0])\n",
        "\n",
        "    distrib = res.logits\n",
        "    logits = distrib[0][-1]\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the top 10 tokens and their probabilities\n",
        "    top_k = 50\n",
        "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "    # Convert indices to tokens\n",
        "    top_k_tokens = [tokenizer.decode(index.item()) for index in top_k_indices]\n",
        "\n",
        "    # Collect the data\n",
        "    data_temp = []\n",
        "    for token, prob in zip(top_k_tokens, top_k_probs):\n",
        "        data_temp.append({\n",
        "            \"token\": token,\n",
        "            \"prob\": prob.detach().cpu().item()\n",
        "        })\n",
        "\n",
        "    data_entry.append({\"run\": \"clean\", \"top_100\": data_temp})\n",
        "\n",
        "    ###############################################\n",
        "    # Interchange Interventions across layer sets #\n",
        "    ###############################################\n",
        "\n",
        "    # Get the index of the last token using len()\n",
        "    last_token_index = len(base['input_ids'][0]) - 1  # Use len() to get the length of the sequence\n",
        "\n",
        "    # Create intervention for specific layers\n",
        "    config = pv.IntervenableConfig([{\n",
        "        \"layer\": l,\n",
        "        \"component\": \"mlp_output\",\n",
        "        \"intervention_type\": VanillaIntervention\n",
        "        } for l in layer_set] # Pass a list instead of a single layer\n",
        "    )\n",
        "\n",
        "    pv_model = pv.IntervenableModel(config, model=model)\n",
        "\n",
        "    # Define list of subspaces based on the layer_subspaces_map\n",
        "    # Create an empty list to store the corresponding subspaces for each layer in layer_set\n",
        "    subspaces = []\n",
        "\n",
        "    # Loop over the layers in the current layer_set and fetch corresponding subspaces\n",
        "    for layer in layer_set:\n",
        "        subspaces.append(layer_subspaces_map[layer])\n",
        "\n",
        "    # run an interchange intervention\n",
        "    _, intervened_outputs = pv_model(\n",
        "      # the base input\n",
        "      base=tokenizer(sentence, return_tensors = \"pt\").to(device),\n",
        "      # the source input\n",
        "      sources=tokenizer(sentence_intervention, return_tensors = \"pt\").to(device),\n",
        "      # the location to intervene at (last token)\n",
        "      unit_locations={\"sources->base\": last_token_index},\n",
        "      subspaces = subspaces\n",
        "    )\n",
        "\n",
        "    distrib = intervened_outputs.logits\n",
        "    logits = distrib[0][-1]\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the top 10 tokens and their probabilities\n",
        "    top_k = 100\n",
        "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "    # Convert indices to tokens\n",
        "    top_k_tokens = [tokenizer.decode(index.item()) for index in top_k_indices]\n",
        "\n",
        "    # Collect the data\n",
        "    data_temp = []\n",
        "    for token, prob in zip(top_k_tokens, top_k_probs):\n",
        "        data_temp.append({\n",
        "            \"token\": token,\n",
        "            \"prob\": prob.detach().cpu().item()\n",
        "        })\n",
        "\n",
        "    data_entry.append({\"run\": \"intervened\", \"top_100\": data_temp})\n",
        "\n",
        "    df = pd.DataFrame(data_entry)\n",
        "\n",
        "    output_dir = f\"Interventions/\"\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create the folder if it doesn't exist\n",
        "\n",
        "    df.to_csv(f\"{output_dir}/intervention_{model_name}_{task}_{operand}_{label}_threshold_{threshold}_{j}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKkH5cxIRo_f"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6r3yhnLRou_",
        "outputId": "cec0fd06-36fe-495f-e539-1cc671f9c1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing example 157 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_157.csv\n",
            "Processing example 193 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_193.csv\n",
            "Processing example 71 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_71.csv\n",
            "Processing example 155 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_155.csv\n",
            "Processing example 177 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_177.csv\n",
            "Processing example 69 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_69.csv\n",
            "Processing example 97 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_97.csv\n",
            "Processing example 191 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_191.csv\n",
            "Processing example 106 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_106.csv\n",
            "Processing example 95 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_95.csv\n",
            "Processing example 4 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_4.csv\n",
            "Processing example 180 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_180.csv\n",
            "Processing example 138 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_138.csv\n",
            "Processing example 22 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_22.csv\n",
            "Processing example 150 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_150.csv\n",
            "Processing example 16 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_16.csv\n",
            "Processing example 72 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_72.csv\n",
            "Processing example 151 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_151.csv\n",
            "Processing example 139 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_139.csv\n",
            "Processing example 123 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_123.csv\n",
            "Processing example 84 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_84.csv\n",
            "Processing example 107 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_107.csv\n",
            "Processing example 88 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_88.csv\n",
            "Processing example 143 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_143.csv\n",
            "Processing example 7 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_7.csv\n",
            "Processing example 78 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_78.csv\n",
            "Processing example 62 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_62.csv\n",
            "Processing example 161 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_161.csv\n",
            "Processing example 130 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_130.csv\n",
            "Processing example 29 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_29.csv\n",
            "Processing example 44 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_44.csv\n",
            "Processing example 146 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_146.csv\n",
            "Processing example 89 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_89.csv\n",
            "Processing example 159 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_159.csv\n",
            "Processing example 17 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_17.csv\n",
            "Processing example 96 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_96.csv\n",
            "Processing example 49 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_49.csv\n",
            "Processing example 19 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_19.csv\n",
            "Processing example 196 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_196.csv\n",
            "Processing example 41 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_41.csv\n",
            "Processing example 156 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_156.csv\n",
            "Processing example 55 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_55.csv\n",
            "Processing example 185 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_185.csv\n",
            "Processing example 165 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_165.csv\n",
            "Processing example 119 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_119.csv\n",
            "Processing example 162 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_162.csv\n",
            "Processing example 170 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_170.csv\n",
            "Processing example 87 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_87.csv\n",
            "Processing example 136 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_136.csv\n",
            "Processing example 8 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_8.csv\n",
            "Processing example 65 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_65.csv\n",
            "Processing example 160 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_160.csv\n",
            "Processing example 134 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_134.csv\n",
            "Processing example 46 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_46.csv\n",
            "Processing example 53 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_53.csv\n",
            "Processing example 132 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_132.csv\n",
            "Processing example 91 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_91.csv\n",
            "Processing example 23 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_23.csv\n",
            "Processing example 0 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_0.csv\n",
            "Processing example 100 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_100.csv\n",
            "Processing example 108 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_108.csv\n",
            "Processing example 40 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_40.csv\n",
            "Processing example 80 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_80.csv\n",
            "Processing example 120 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_120.csv\n",
            "Processing example 192 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_192.csv\n",
            "Processing example 179 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_179.csv\n",
            "Processing example 77 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_77.csv\n",
            "Processing example 1 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_1.csv\n",
            "Processing example 154 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_154.csv\n",
            "Processing example 171 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_171.csv\n",
            "Processing example 117 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_117.csv\n",
            "Processing example 125 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_125.csv\n",
            "Processing example 172 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_172.csv\n",
            "Processing example 35 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_35.csv\n",
            "Processing example 37 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_37.csv\n",
            "Processing example 81 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_81.csv\n",
            "Processing example 82 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_82.csv\n",
            "Processing example 75 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_75.csv\n",
            "Processing example 104 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_104.csv\n",
            "Processing example 195 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_195.csv\n",
            "Processing example 189 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_189.csv\n",
            "Processing example 129 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_129.csv\n",
            "Processing example 93 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_93.csv\n",
            "Processing example 24 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_24.csv\n",
            "Processing example 79 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_79.csv\n",
            "Processing example 126 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_126.csv\n",
            "Processing example 145 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_145.csv\n",
            "Processing example 54 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_54.csv\n",
            "Processing example 70 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_70.csv\n",
            "Processing example 85 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_85.csv\n",
            "Processing example 111 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_111.csv\n",
            "Processing example 121 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_121.csv\n",
            "Processing example 133 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_133.csv\n",
            "Processing example 36 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_36.csv\n",
            "Processing example 152 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_152.csv\n",
            "Processing example 94 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_94.csv\n",
            "Processing example 58 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_58.csv\n",
            "Processing example 68 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_68.csv\n",
            "Processing example 127 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_127.csv\n",
            "Processing example 166 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_166.csv\n",
            "Processing example 174 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_174.csv\n",
            "Processing example 67 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_67.csv\n",
            "Processing example 164 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_164.csv\n",
            "Processing example 66 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_66.csv\n",
            "Processing example 51 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_51.csv\n",
            "Processing example 20 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_20.csv\n",
            "Processing example 99 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_99.csv\n",
            "Processing example 105 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_105.csv\n",
            "Processing example 144 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_144.csv\n",
            "Processing example 31 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_31.csv\n",
            "Processing example 122 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_122.csv\n",
            "Processing example 11 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_11.csv\n",
            "Processing example 34 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_34.csv\n",
            "Processing example 32 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_32.csv\n",
            "Processing example 194 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_194.csv\n",
            "Processing example 131 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_131.csv\n",
            "Processing example 86 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_86.csv\n",
            "Processing example 187 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_187.csv\n",
            "Processing example 73 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_73.csv\n",
            "Processing example 30 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_30.csv\n",
            "Processing example 5 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_5.csv\n",
            "Processing example 76 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_76.csv\n",
            "Processing example 199 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_199.csv\n",
            "Processing example 188 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_188.csv\n",
            "Processing example 124 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_124.csv\n",
            "Processing example 9 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_9.csv\n",
            "Processing example 142 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_142.csv\n",
            "Processing example 45 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_45.csv\n",
            "Processing example 28 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_28.csv\n",
            "Processing example 168 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_168.csv\n",
            "Processing example 52 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_52.csv\n",
            "Processing example 116 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_116.csv\n",
            "Processing example 74 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_74.csv\n",
            "Processing example 197 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_197.csv\n",
            "Processing example 167 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_167.csv\n",
            "Processing example 12 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_12.csv\n",
            "Processing example 27 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_27.csv\n",
            "Processing example 98 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_98.csv\n",
            "Processing example 60 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_60.csv\n",
            "Processing example 64 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_64.csv\n",
            "Processing example 176 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_176.csv\n",
            "Processing example 15 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_15.csv\n",
            "Processing example 183 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_183.csv\n",
            "Processing example 149 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_149.csv\n",
            "Processing example 38 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_38.csv\n",
            "Processing example 109 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_109.csv\n",
            "Processing example 137 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_137.csv\n",
            "Processing example 25 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_25.csv\n",
            "Processing example 178 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_178.csv\n",
            "Processing example 3 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_3.csv\n",
            "Processing example 48 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_48.csv\n",
            "Processing example 42 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_42.csv\n",
            "Processing example 181 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_181.csv\n",
            "Processing example 63 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_63.csv\n",
            "Processing example 153 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_153.csv\n",
            "Processing example 182 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_182.csv\n",
            "Processing example 10 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_10.csv\n",
            "Processing example 114 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_114.csv\n",
            "Processing example 190 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_190.csv\n",
            "Processing example 26 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_26.csv\n",
            "Processing example 13 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_13.csv\n",
            "Processing example 184 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_184.csv\n",
            "Processing example 57 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_57.csv\n",
            "Processing example 148 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_148.csv\n",
            "Processing example 14 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_14.csv\n",
            "Processing example 56 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_56.csv\n",
            "Processing example 61 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_61.csv\n",
            "Processing example 103 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_103.csv\n",
            "Processing example 83 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_83.csv\n",
            "Processing example 186 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_186.csv\n",
            "Processing example 128 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_128.csv\n",
            "Processing example 110 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_110.csv\n",
            "Processing example 102 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_102.csv\n",
            "Processing example 50 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_50.csv\n",
            "Processing example 90 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_90.csv\n",
            "Processing example 92 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_92.csv\n",
            "Processing example 198 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_198.csv\n",
            "Processing example 59 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_59.csv\n",
            "Processing example 158 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_158.csv\n",
            "Processing example 118 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_118.csv\n",
            "Processing example 2 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_2.csv\n",
            "Processing example 39 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_39.csv\n",
            "Processing example 175 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_175.csv\n",
            "Processing example 141 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_141.csv\n",
            "Processing example 173 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_173.csv\n",
            "Processing example 43 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_43.csv\n",
            "Processing example 112 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_112.csv\n",
            "Processing example 163 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_163.csv\n",
            "Processing example 147 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_147.csv\n",
            "Processing example 101 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_101.csv\n",
            "Processing example 47 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_47.csv\n",
            "Processing example 33 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_33.csv\n",
            "Processing example 115 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_115.csv\n",
            "Processing example 169 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_169.csv\n",
            "Processing example 113 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_113.csv\n",
            "Processing example 18 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_18.csv\n",
            "Processing example 140 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_140.csv\n",
            "Processing example 135 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_135.csv\n",
            "Processing example 21 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_21.csv\n",
            "Processing example 6 from file intervention_Llama-3-8B_addition_op1_hundredth_threshold_0.8_6.csv\n",
            "Averages computed and saved to average_probabilities.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "\n",
        "variant_labels = [\"bbb\", \"bbs\", \"bsb\", \"bss\", \"sbb\", \"sbs\", \"ssb\", \"sss\"]\n",
        "folder_path = \"Interventions/\"\n",
        "\n",
        "# Initialize accumulators: sums and counts for each run and variant label\n",
        "accumulated_probs = {\n",
        "    \"clean\": {label: 0.0 for label in variant_labels},\n",
        "    \"intervened\": {label: 0.0 for label in variant_labels}\n",
        "}\n",
        "counts = {\n",
        "    \"clean\": {label: 0 for label in variant_labels},\n",
        "    \"intervened\": {label: 0 for label in variant_labels}\n",
        "}\n",
        "\n",
        "# Get sorted CSV files\n",
        "csv_files = [f for f in os.listdir(folder_path) if re.match(r\"intervention_.*_(\\d+)\\.csv\", f)]\n",
        "csv_files.sort(key=lambda x: int(re.search(r\"_(\\d+)\", x).group(1)))\n",
        "\n",
        "for file_name in csv_files:\n",
        "    index_match = re.search(r\"_(\\d+)\\.csv$\", file_name)\n",
        "    i = int(index_match.group(1)) if index_match else None\n",
        "    if i is None:\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing example {i} from file {file_name}\")\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Map variant labels to target tokens from your loaded `data`\n",
        "    variant_token_map = {k: str(v) for k, v in data[i][\"result_variants\"].items()}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        run_type = row[\"run\"]  # \"clean\" or \"intervened\"\n",
        "        try:\n",
        "            token_probs = ast.literal_eval(row[\"top_100\"])\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing token probs in {file_name}, run={run_type}: {e}\")\n",
        "            continue\n",
        "\n",
        "        for variant_label, target_token in variant_token_map.items():\n",
        "            for entry in token_probs:\n",
        "                if entry[\"token\"] == target_token:\n",
        "                    prob = entry[\"prob\"]\n",
        "                    accumulated_probs[run_type][variant_label] += prob\n",
        "                    counts[run_type][variant_label] += 1\n",
        "\n",
        "# Compute averages over all examples and all files\n",
        "averages = {\n",
        "    run_type: {\n",
        "        label: (accumulated_probs[run_type][label] / counts[run_type][label]) if counts[run_type][label] > 0 else 0\n",
        "        for label in variant_labels\n",
        "    }\n",
        "    for run_type in [\"clean\", \"intervened\"]\n",
        "}\n",
        "\n",
        "# Save averages to JSON\n",
        "output_file = \"average_probabilities.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(averages, f, indent=4)\n",
        "\n",
        "print(\"Averages computed and saved to\", output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBVJb4Q6RvHe"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "vXWGFMQXRwq2",
        "outputId": "8b546b1c-b903-4df7-bd2d-fc8dc0e8b610"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `averages` dict is computed as before:\n",
        "# averages = {\n",
        "#   \"clean\": {...},\n",
        "#   \"intervened\": {...}\n",
        "# }\n",
        "\n",
        "variant_labels = list(averages[\"clean\"].keys())\n",
        "\n",
        "clean_vals = [averages[\"clean\"][label] for label in variant_labels]\n",
        "intervened_vals = [averages[\"intervened\"][label] for label in variant_labels]\n",
        "diff_vals = [i - c for i, c in zip(intervened_vals, clean_vals)]\n",
        "\n",
        "x = np.arange(len(variant_labels))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "bars1 = ax.bar(x - width, clean_vals, width, label='Clean', color='tab:blue')\n",
        "bars2 = ax.bar(x, intervened_vals, width, label='Intervened', color='tab:orange')\n",
        "bars3 = ax.bar(x + width, diff_vals, width, label='Difference (Clean - Intervened)', color='tab:green')\n",
        "\n",
        "ax.set_ylabel('Average Probability')\n",
        "ax.set_title('Average Probabilities per Variant Label')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(variant_labels)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttJlKtm9Ry8G"
      },
      "source": [
        "## Flip Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARa_JDyRR0Qv",
        "outputId": "dab330fb-6966-4f43-ffa6-c03c7e1fae13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Flip Rate (from 'bbb' → 'sbb') = 0.605 over 200 examples.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import ast\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "import sys\n",
        "\n",
        "# Flip rate calculation\n",
        "expected_variant_map = {\n",
        "    \"unit\": \"bbs\",\n",
        "    \"tenth\": \"bsb\",\n",
        "    \"hundredth\": \"sbb\"\n",
        "}\n",
        "\n",
        "# Use your current label to find the expected variant\n",
        "expected_variant = expected_variant_map[label]  # 'label' must be defined in your loop or global scope\n",
        "\n",
        "flip_count = 0\n",
        "total_count = 0\n",
        "\n",
        "for file_name in csv_files:\n",
        "    index_match = re.search(r\"_(\\d+)\\.csv$\", file_name)\n",
        "    i = int(index_match.group(1)) if index_match else None\n",
        "    if i is None:\n",
        "        continue\n",
        "\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Get token mapping for this datapoint\n",
        "    variant_token_map = {k: str(v) for k, v in data[i][\"result_variants\"].items()}\n",
        "\n",
        "    # Dictionary to store best variant per run\n",
        "    best_variant = {}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        run_type = row[\"run\"]\n",
        "        try:\n",
        "            token_probs = ast.literal_eval(row[\"top_100\"])\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing token probs in {file_name}, run={run_type}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Find the best matching variant for this run\n",
        "        highest_prob = -1\n",
        "        predicted_variant = None\n",
        "\n",
        "        for variant_label, token in variant_token_map.items():\n",
        "            for entry in token_probs:\n",
        "                if entry[\"token\"] == token:\n",
        "                    if entry[\"prob\"] > highest_prob:\n",
        "                        highest_prob = entry[\"prob\"]\n",
        "                        predicted_variant = variant_label\n",
        "\n",
        "        best_variant[run_type] = predicted_variant\n",
        "\n",
        "    # Count flip: clean was bbb, intervened is expected variant\n",
        "    if best_variant.get(\"clean\") == \"bbb\" and best_variant.get(\"intervened\") == expected_variant:\n",
        "        flip_count += 1\n",
        "\n",
        "    total_count += 1\n",
        "\n",
        "flip_rate = flip_count / total_count if total_count > 0 else 0\n",
        "print(f\"\\n Flip Rate (from 'bbb' → '{expected_variant}') = {flip_rate:.3f} over {total_count} examples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq017nNDx9XV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e6c85bb6afa446e8c22b9bdecf9ebac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6cd96f2861df485c98963cee8fd11f9f",
            "placeholder": "​",
            "style": "IPY_MODEL_294edc2636974381973a4981ca576e96",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "11644d5a8dbb4bd8a17cee2967f09c44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd8359385d4473b9249736a61dbc9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_34a5cea0e4f344ee999db2d8b94023ae",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67b063795012434ca84fda35af94a22f",
            "tabbable": null,
            "tooltip": null,
            "value": 4
          }
        },
        "294edc2636974381973a4981ca576e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "34a5cea0e4f344ee999db2d8b94023ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af381af35af4fe1a99c1a827ce069ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_11644d5a8dbb4bd8a17cee2967f09c44",
            "placeholder": "​",
            "style": "IPY_MODEL_c69045c248594ea594850243be21de93",
            "tabbable": null,
            "tooltip": null,
            "value": " 4/4 [00:03&lt;00:00,  1.27it/s]"
          }
        },
        "67b063795012434ca84fda35af94a22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cd96f2861df485c98963cee8fd11f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69045c248594ea594850243be21de93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e77b709fd4c04e1aa8162558af5b40fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed08da4944744403baedc3abacf26a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e6c85bb6afa446e8c22b9bdecf9ebac",
              "IPY_MODEL_1fd8359385d4473b9249736a61dbc9ef",
              "IPY_MODEL_4af381af35af4fe1a99c1a827ce069ef"
            ],
            "layout": "IPY_MODEL_e77b709fd4c04e1aa8162558af5b40fa",
            "tabbable": null,
            "tooltip": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
