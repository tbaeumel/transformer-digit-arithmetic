# transformer-digit-arithmetic
Data and Code for 'Transformer Language Models Solve Simple Arithmetic Tasks Digit-by-Digit'

Datasets: 
D_add, op1 
D_add, op2
D_sub, op1
D_sub, op2

Sets of Fisher Neurons: 
(for the best thresholds only)
3 models x 3 digit positions x 2 operators

Script: 
Intervention on subspaces + visualization of prob change + flip rate
(Note: Olmo2 requires an extension of pyvene to the olmo 2 model which is on  my own github and therefore not anonymous - needs to also be anonymized)

------------------
Also need code to select digit-position circuit members? 
Or the code for the single layer interventions?
